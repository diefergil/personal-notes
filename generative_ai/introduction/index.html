<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="My personal notes" name="description"/><meta content="Diego" name="author"/><link href="https://diefergil.github.io/personal-notes/generative_ai/introduction/" rel="canonical"/><link href="../../cloud/google/Bigquery/" rel="prev"/><link href="../nlp/Natural%20Language%20Processing/" rel="next"/><link href="../../assets/images/favicon.png" rel="icon"/><meta content="mkdocs-1.4.3, mkdocs-material-9.1.20" name="generator"/><title>Introduction - My personal notes</title><link href="../../assets/stylesheets/main.eebd395e.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/palette.ecc896b0.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href="../../css/timeago.css" rel="stylesheet"/><link href="../../stylesheets/extra.css" rel="stylesheet"/><link href="../../stylesheets/links.css" rel="stylesheet"/><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-6S6TNHYVRT"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-6S6TNHYVRT",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-6S6TNHYVRT",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script></head> <body data-md-color-accent="light-blue" data-md-color-primary="blue-grey" data-md-color-scheme="default" dir="ltr"> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" for="__drawer"></label> <div data-md-component="skip"> <a class="md-skip" href="#generative-ai"> Skip to content </a> </div> <div data-md-component="announce"> <aside class="md-banner"> <div class="md-banner__inner md-grid md-typeset"> For updates subscribe to the <a href="https://diefergil.github.io/personal-notes/newsletter/0_newsletter_index/"><strong>RSS feed</strong></a> <img height="15" src="/personal-notes/img/orange_logo.png" width="15"/> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component="header"> <nav aria-label="Header" class="md-header__inner md-grid"> <a aria-label="My personal notes" class="md-header__button md-logo" data-md-component="logo" href="../.." title="My personal notes"> <img alt="logo" src="../../img/logo.bmp"/> </a> <label class="md-header__button md-icon" for="__drawer"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class="md-header__title" data-md-component="header-title"> <div class="md-header__ellipsis"> <div class="md-header__topic"> <span class="md-ellipsis"> My personal notes </span> </div> <div class="md-header__topic" data-md-component="header-topic"> <span class="md-ellipsis"> Introduction </span> </div> </div> </div> <form class="md-header__option" data-md-component="palette"> <input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="light-blue" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="blue-grey" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"></path></svg> </label> <input aria-label="Switch to light mode" class="md-option" data-md-color-accent="light-blue" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="blue-grey" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"></path></svg> </label> </form> <label class="md-header__button md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/> <label class="md-search__icon md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label="Search" class="md-search__options"> <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> <div class="md-search__suggest" data-md-component="search-suggest"></div> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="search-result"> <div class="md-search-result__meta"> Initializing search </div> <ol class="md-search-result__list" role="presentation"></ol> </div> </div> </div> </div> </div> <div class="md-header__source"> <a class="md-source" data-md-component="source" href="https://github.com/diefergil/personal-notes" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> diefergil/personal-notes </div> </a> </div> </nav> </header> <div class="md-container" data-md-component="container"> <main class="md-main" data-md-component="main"> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title" for="__drawer"> <a aria-label="My personal notes" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="My personal notes"> <img alt="logo" src="../../img/logo.bmp"/> </a> My personal notes </label> <div class="md-nav__source"> <a class="md-source" data-md-component="source" href="https://github.com/diefergil/personal-notes" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> diefergil/personal-notes </div> </a> </div> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.."> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/> <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0"> Cloud <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_2"> <span class="md-nav__icon md-icon"></span> Cloud </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_2_1" type="checkbox"/> <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0"> AWS <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_2_1_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_2_1"> <span class="md-nav__icon md-icon"></span> AWS </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/app_runner/"> App Runner </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/batch/"> Batch </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/lambda/"> Lambda functions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/steps/"> Steps </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_2_2" type="checkbox"/> <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0"> Google Cloud <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_2_2_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_2_2"> <span class="md-nav__icon md-icon"></span> Google Cloud </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/gcloud/"> gcloud CLI </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/app_engine/"> App Engine </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/cloud_functions/"> Cloud Functions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/cloud_run/"> Cloud Run </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/Bigquery/"> Bigquery </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/> <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0"> Generative AI <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_3"> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> Introduction <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href="./"> Introduction </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#generative-ai"> Generative AI </a> <nav aria-label="Generative AI" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#terminology"> Terminology </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#llms"> LLMs </a> <nav aria-label="LLMs" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#definition"> Definition </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#foundation-model"> Foundation Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#pre-training-large-language-models"> Pre-training Large Language Models </a> <nav aria-label="Pre-training Large Language Models" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#initial-training-process-pre-training"> Initial Training Process (Pre-training) </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-objectives-for-transformer-variants"> Training Objectives for Transformer Variants </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#transformers"> Transformers </a> <nav aria-label="Transformers" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#encoder-only-models"> Encoder-only Models </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#decoder-only-models"> Decoder-only Models </a> <nav aria-label="Decoder-only Models" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#encoder-decoder-models-sequence-to-sequence-models"> Encoder-Decoder Models (Sequence-to-Sequence Models) </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#attention-scores"> Attention Scores </a> <nav aria-label="Attention Scores" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#types"> Types </a> <nav aria-label="Types" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#multiplicative-attention-dot-product-attention"> Multiplicative Attention (Dot-Product Attention) </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#additive-attention"> Additive Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#general-attention"> General Attention </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#attention-mechanisms"> Attention Mechanisms </a> <nav aria-label="Attention Mechanisms" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#self-attention"> Self-Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#multi-head-attention"> Multi-Head Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#multi-query-attention"> Multi-Query Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#cross-attention"> Cross-Attention </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#attention-problems-and-solutions"> Attention problems and solutions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#positional-embeddings"> Positional Embeddings </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#residual-connections"> Residual Connections </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#layer-normalization"> Layer Normalization </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#prompting-and-prompt-engineering"> Prompting and Prompt Engineering </a> <nav aria-label="Prompting and Prompt Engineering" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#prompting"> Prompting </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#prompt-engineering"> Prompt Engineering </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#in-context-learning-icl"> In-Context Learning (ICL) </a> <nav aria-label="In-Context Learning (ICL)" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#zero-shot-inference"> Zero-Shot Inference </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#few-shot-inference"> Few-Shot Inference </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#inference-configuration-parameters"> Inference Configuration Parameters </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#virtuous-feedback-loops"> Virtuous Feedback Loops </a> <nav aria-label="Virtuous Feedback Loops" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#workflow-to-try-prompts"> Workflow to try prompts </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#data"> Data </a> <nav aria-label="Data" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#most-common-sources"> Most common sources </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#generating-traing-data-with-llms"> Generating traing data with LLMs </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#resources"> Resources </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../nlp/Natural%20Language%20Processing/"> NLP </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/> <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0"> Adapting foundational models <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_3"> <span class="md-nav__icon md-icon"></span> Adapting foundational models </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../prompting/"> Prompting </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Fine%20Tuning/"> Instruction Fine-Tuning </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Reinforcement%20Learning%20From%20Human%20Feedback/"> Reinforcement Learning From Human Feedback </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../probing/"> Probing </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Evaluate%20LLMs/"> Evaluation </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Deploy%20LLMS/"> Deployment </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_6" type="checkbox"/> <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0"> HuggingFace <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_6_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_6"> <span class="md-nav__icon md-icon"></span> HuggingFace </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../huggingface/"> Overview </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/hugginface_intro/"> Hugginface Intro </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/hugging-face-tokenizer/"> Using Hugging Face Tokenizers </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/diffusers/"> Diffusion models and the library from ü§ó </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_7" type="checkbox"/> <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0"> Embeddings <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_7_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_7"> <span class="md-nav__icon md-icon"></span> Embeddings </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/lance_db/"> Vector Database Basics </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/lance_db_multimodal/"> Multimodal Search </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8" type="checkbox"/> <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0"> Tutorials <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_8_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_8"> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/pytorch_intro/"> Pytorch </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8_2" type="checkbox"/> <div class="md-nav__link md-nav__link--index"> <a href="../tutorials/try_promt_techniques/">Promting techninques review</a> <label for="__nav_3_8_2"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="false" aria-labelledby="__nav_3_8_2_label" class="md-nav" data-md-level="3"> <label class="md-nav__title" for="__nav_3_8_2"> <span class="md-nav__icon md-icon"></span> Promting techninques review </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/Building_QA_Datasets/"> Building Question Answering Datasets </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/wikipedia_qa/"> Wikipedia QA Opean AI example </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/example_ReAcT_prompt/"> React promt example </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/openai_functions/"> Open AI call function </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain_examples/"> Langchain introduction </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8_6" type="checkbox"/> <label class="md-nav__link" for="__nav_3_8_6" id="__nav_3_8_6_label" tabindex="0"> Transfer Learning <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_8_6_label" class="md-nav" data-md-level="3"> <label class="md-nav__title" for="__nav_3_8_6"> <span class="md-nav__icon md-icon"></span> Transfer Learning </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/transfer-learning-mobilenet/"> Exercise: Transfer learning using MobileNetV3 </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/train_gans/"> Generative Adversarial Network: training </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/training_DDPM/"> Train a Denoising Diffusion Probabilistic Model from scratch </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8_9" type="checkbox"/> <div class="md-nav__link md-nav__link--index"> <a href="../tutorials/langchain/snnipets/">Langchain</a> <label for="__nav_3_8_9"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="false" aria-labelledby="__nav_3_8_9_label" class="md-nav" data-md-level="3"> <label class="md-nav__title" for="__nav_3_8_9"> <span class="md-nav__icon md-icon"></span> Langchain </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/Lesson_2_Student/"> Lesson 2 : LangGraph Components </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/Lesson_4_Student/"> Lesson 4: Persistence and Streaming </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/Lesson_5_Student/"> Lesson 5: Human in the Loop </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/helper/"> Helper </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/functions/L2-lcel-student/"> LangChain Expression Language (LCEL) </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/functions/L5-tools-routing-apis-student/"> Tools and Routing </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/functions/L6-functional_conversation-student/"> Conversational agent </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/> <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0"> Mlops <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_4"> <span class="md-nav__icon md-icon"></span> Mlops </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/mlops_intro/"> Introduction </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/continous_delivery/"> Continous integration </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_4_3" type="checkbox"/> <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0"> Tools <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_4_3_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_4_3"> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/tools/Docker/"> Docker </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/tools/github_actions/"> Github actions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/tools/makefile/"> Makefile </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5" type="checkbox"/> <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0"> Python <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_5"> <span class="md-nav__icon md-icon"></span> Python </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_1" type="checkbox"/> <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0"> API's <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_1_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_1"> <span class="md-nav__icon md-icon"></span> API's </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/apis/best_practices/"> Best practices </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/apis/fastapi/"> FastAPI </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/apis/flask/"> Flask </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_2" type="checkbox"/> <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0"> CLI's <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_2_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_2"> <span class="md-nav__icon md-icon"></span> CLI's </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/cli/argparse/"> Argparse </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/cli/click/"> Click </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_3" type="checkbox"/> <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0"> Environments <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_3_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_3"> <span class="md-nav__icon md-icon"></span> Environments </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/environments/"> Virtual environments </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_4" type="checkbox"/> <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0"> Packaging <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_4_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_4"> <span class="md-nav__icon md-icon"></span> Packaging </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/packaging/setuptools/"> Setuptools </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/packaging/Poetry/"> Poetry </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_5" type="checkbox"/> <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0"> Tests <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_5_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_5"> <span class="md-nav__icon md-icon"></span> Tests </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/pytest/"> Pytests </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/> <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0"> Infrastructure <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_6"> <span class="md-nav__icon md-icon"></span> Infrastructure </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../IAC/Pulumi/"> Pulumi </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../IAC/Terraform/"> Terraform </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../about/"> About </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#generative-ai"> Generative AI </a> <nav aria-label="Generative AI" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#terminology"> Terminology </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#llms"> LLMs </a> <nav aria-label="LLMs" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#definition"> Definition </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#foundation-model"> Foundation Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#pre-training-large-language-models"> Pre-training Large Language Models </a> <nav aria-label="Pre-training Large Language Models" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#initial-training-process-pre-training"> Initial Training Process (Pre-training) </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-objectives-for-transformer-variants"> Training Objectives for Transformer Variants </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#transformers"> Transformers </a> <nav aria-label="Transformers" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#encoder-only-models"> Encoder-only Models </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#decoder-only-models"> Decoder-only Models </a> <nav aria-label="Decoder-only Models" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#encoder-decoder-models-sequence-to-sequence-models"> Encoder-Decoder Models (Sequence-to-Sequence Models) </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#attention-scores"> Attention Scores </a> <nav aria-label="Attention Scores" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#types"> Types </a> <nav aria-label="Types" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#multiplicative-attention-dot-product-attention"> Multiplicative Attention (Dot-Product Attention) </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#additive-attention"> Additive Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#general-attention"> General Attention </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#attention-mechanisms"> Attention Mechanisms </a> <nav aria-label="Attention Mechanisms" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#self-attention"> Self-Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#multi-head-attention"> Multi-Head Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#multi-query-attention"> Multi-Query Attention </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#cross-attention"> Cross-Attention </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#attention-problems-and-solutions"> Attention problems and solutions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#positional-embeddings"> Positional Embeddings </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#residual-connections"> Residual Connections </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#layer-normalization"> Layer Normalization </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#prompting-and-prompt-engineering"> Prompting and Prompt Engineering </a> <nav aria-label="Prompting and Prompt Engineering" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#prompting"> Prompting </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#prompt-engineering"> Prompt Engineering </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#in-context-learning-icl"> In-Context Learning (ICL) </a> <nav aria-label="In-Context Learning (ICL)" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#zero-shot-inference"> Zero-Shot Inference </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#few-shot-inference"> Few-Shot Inference </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#inference-configuration-parameters"> Inference Configuration Parameters </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#virtuous-feedback-loops"> Virtuous Feedback Loops </a> <nav aria-label="Virtuous Feedback Loops" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#workflow-to-try-prompts"> Workflow to try prompts </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#data"> Data </a> <nav aria-label="Data" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#most-common-sources"> Most common sources </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#generating-traing-data-with-llms"> Generating traing data with LLMs </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#resources"> Resources </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-content" data-md-component="content"> <article class="md-content__inner md-typeset"> <!-- Google AdSense Code --> <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4806129530093947"></script> <!-- End Google AdSense Code --> <nav class="md-tags"> <span class="md-tag">resource</span> </nav> <h1>Introduction</h1> <h2 id="generative-ai">Generative AI<a class="headerlink" href="#generative-ai" title="Permanent link">‚öë</a></h2> <p>It is a subset of traditional ML. The ML algorithms that work behind generative AI do so by exploiting the statistical patterns present in the massive datasets of content that was originally generated by humans.</p> <h3 id="terminology">Terminology<a class="headerlink" href="#terminology" title="Permanent link">‚öë</a></h3> <ul> <li>Prompt: The input given to an LLM is called the prompt.</li> <li>Context Window: The space/memory that is available to the prompt is called the context window. It is essentially the maximum size of the prompt that the model can handle before it performs poorly. It is limited to a few thousand of words but also varies model to model.</li> <li>Completion: The output of the an LLM when given a prompt is called the completion. Generally, the completion consists of the prompt and the text generated by the model by repeatedly generating the next token or word, though almost all applications omit the prompt from the model‚Äôs output when showing it to users</li> </ul> <h3 id="llms">LLMs<a class="headerlink" href="#llms" title="Permanent link">‚öë</a></h3> <h4 id="definition">Definition<a class="headerlink" href="#definition" title="Permanent link">‚öë</a></h4> <p>LLMs (Large Language Models) are generative AI models specifically designed to understand text. All LLMs are powered by the Transformer (Google, 2017) architecture. They are designed to take in input text and repeatedly generate the next token or word that appropriately ‚Äúcompletes‚Äù the input text. For example, an LLM can be given the input: Where is Ganymede located in the solar system? In response, the LLM might generate the following output: Ganymede is a moon of Jupiter and is located in the solar system within Jupiter‚Äôs orbit. Here, the model essentially completed the given input by repeatedly generating the next word or token that fits appropriately. These models have abilities beyond just language and are capable of breaking down complex tasks, reasoning and problem solving. It is commonly accepted that as the size (in terms of number of parameters) of an LLM increases, so does its understanding of language. At the same time, it is also true the smaller models can be fine-tuned to perform well on specific tasks.</p> <h3 id="foundation-model">Foundation Model<a class="headerlink" href="#foundation-model" title="Permanent link">‚öë</a></h3> <p>A foundation model is a powerful AI tool that can do many different things after being trained on lots of diverse data. These models are incredibly versatile and provide a solid base for creating various AI applications, like a strong foundation holds up different kind of buildings. By using a foundation model, we have a strong starting point for building specialized AI tasks.</p> <p>Foundation Models (GPT, BERT) and Traditional Models (Linear regression, SVM) are two distinct approaches in the field of artificial intelligence with different strengths. Foundation Models, which are built on large, diverse datasets, have the incredible ability to adapt and perform well on many different tasks. In contrast, Traditional Models specialize in specific tasks by learning from smaller, focused datasets, making them more straightforward and efficient for targeted applications.</p> <h3 id="pre-training-large-language-models">Pre-training Large Language Models<a class="headerlink" href="#pre-training-large-language-models" title="Permanent link">‚öë</a></h3> <h4 id="initial-training-process-pre-training">Initial Training Process (Pre-training)<a class="headerlink" href="#initial-training-process-pre-training" title="Permanent link">‚öë</a></h4> <p>The initial training process of an LLM is called as pre-training. LLMs work by learning a deep statistical representation of language and this deep representation is developed during pre-training. At a high-level, during pre-training, the model is fed large amounts of unstructured textual data, ranging from gigabytes to petabytes in size. The data is pulled from many sources such as web crawling and corpora of text compiled specifically to train LLMs. The pre-training process is self-supervised. The model internalizes the patterns and structures present in the language. These patterns then unable the model to complete its training objective, which depends on the architecture of the model. In other words, during pre-training, the model weights get updated to minimize the loss of training objective. Clearly, this step requires a lot of compute and the use of GPUs.</p> <p>Additionally, since the data is coming from public sources such as the internet, there is often a data quality filter applied before feeding the data to the LLM so that the training data is of high quality, has low bias and does not have harmful content. Due to this, only about 1-3% of the original tokens are used for pre-training.</p> <h4 id="training-objectives-for-transformer-variants">Training Objectives for Transformer Variants<a class="headerlink" href="#training-objectives-for-transformer-variants" title="Permanent link">‚öë</a></h4> <p>The three configurations of a Transformer are trained with different training objectives and thus, learn to perform different tasks.</p> <p>Popular transformer-based models differ in not only architecture but also pre-training objectives.</p> <ul> <li>Autoregressive (AR): Predicting the next token using its own last output</li> <li>Denoising autoencoder: Predicting tokens based on the pretext that the data has been corrupted</li> <li>Contrastive: Aligning different inputs or views of the same input and constructing (positive, negative) pairs.</li> </ul> <p>Some pre-training objectives are better than others for self-supervised learning; this depends on whether the ground truth can be constructed within the data structure, or whether it requires manual annotation.</p> <h3 id="transformers">Transformers<a class="headerlink" href="#transformers" title="Permanent link">‚öë</a></h3> <p>In mid-2017, Google published <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> and introduced the Transformer model to the world. There are many wonderful works explaining the Transformer model, in particular the <a href="https://jalammar.github.io/illustrated-transformer/">Illustrated Transformer</a> (a wonderful introduction) and the <a href="https://nlp.seas.harvard.edu/annotated-transformer/">Annotated Transformer</a> (with a line-by-line implementation in Python).</p> <p>Transformer architectures consist of building block of self-attention layers.</p> <p>Keep in mind that the original transformer from Vaswani et al. (2017) had both an encoder and a decoder, but that newer transformer-based models often use just the encoder or just the decoder portion.</p> <p><img alt="Transformer detail" src="../../assets/images/transformer-detail.jpeg"/></p> <h4 id="encoder-only-models">Encoder-only Models<a class="headerlink" href="#encoder-only-models" title="Permanent link">‚öë</a></h4> <p>The first LLM to gain broad adoption was <a href="https://arxiv.org/abs/1810.04805">BERT</a> (Bidirectional Encoder Representations from Transformers), an encoder-only model. Encoder-only models are most commonly used as base models for subsequent fine-tuning with a distinct objective, e.g. for the inference-time task of binary classification of movie reviews. (Mask some words)</p> <p>The encoder-only variants of Transformers are also called autoencoding models. They are pre-trained using Masked Language Modeling (MLM). In MLM, tokens in the input sequence are randomly masked and the training objective is to predict the masked tokens in order to reconstruct the original input sequence. This is also called a denoising objective since the masking of the tokens can be thought of as adding noise to the input sequence and then predicting the masked tokens can be thought of as removing that noise from the input sequence. Autoencoding models build bidirectional context representations of the input sequence, meaning that model has an understanding of the full context of the token rather than just the tokens that come before it.</p> <p><img alt="Enconder Only" src="../../assets/images/encoder_only.png"/></p> <p>These models are usually suited to tasks that benefit from this bidirectional context such as sentiment analysis, named entity recognition and word classification, etc. Examples: BERT, ROBERTA.</p> <p>BERT has a denoising autoencoder objective. Specifically, it uses masked language modeling.</p> <p>This means that a fraction of the tokens are masked, and the task for the encoder is to predict those masked words.</p> <p>BERT also optimizes for next sentence prediction. This is fairly different from a next token prediction‚ÄîBERT is not generating the next sentence. It is performing a binary classification of whether or not the second sentence belongs after the first.</p> <h4 id="decoder-only-models">Decoder-only Models<a class="headerlink" href="#decoder-only-models" title="Permanent link">‚öë</a></h4> <p>However, before BERT was released, the first <a href="https://openai.com/research/language-unsupervised">GPT</a> (Generative Pre-Trained Transformer) model, a decoder-only model, was released by OpenAI. Decoder-only models are most commonly used for the inference-time task of text generation. In distinction to encoder-only models, the Transformer's pre-training objective of next token prediction is very similar to the decoder-only model's inference-time task of text generation.</p> <p>The decoder-only variants of Transformers are also called autoregressive models. They are pre-trained using Causal Language Modeling (CLM). In CLM, the training objective is to predict the next token based on the previous sequence of tokens. The tokens of the input sequence are masked and the model can only see the input tokens leading up to the token being predicted at the moment. The model has no knowledge of the tokens that come after this token. The model then iterates over the input sequence one-by-one to predict the next token. Thus, in contrast to autoencoding models, the model builds a unidirectional context for each token.</p> <p><img alt="Deconder Only" src="../../assets/images/decoder_only.png"/></p> <p>By learning to predict the next token from a vast number of examples, the model builds a statistical representation of the language. Predicting the next token is sometimes called full language modeling by researchers. These mode,ls are most suitable for text generation but large autoregressive models also show strong zero-shot inference ability and can perform a variety of tasks. Examples: GPT, BLOOM.</p> <p>GPT has an autoregressive objective. It assumes that there is some kind of continuity or dependency between a value and its predecessors.</p> <p>The attention scores for future tokens are set to negative infinity to prevent "cheating", and then the model proceeds to pick the highest probability candidate for the next token.</p> <p>A technique called "teacher forcing"‚Äîthat has been in use since the 1980s‚Äîcan be used to prevent the model from accumulating mistakes and continuing on a vicious feedback loop during training.</p> <h5 id="encoder-decoder-models-sequence-to-sequence-models">Encoder-Decoder Models (Sequence-to-Sequence Models)<a class="headerlink" href="#encoder-decoder-models-sequence-to-sequence-models" title="Permanent link">‚öë</a></h5> <p>Encoder-Decoder Models (Sequence-to-Sequence Models) The encoder-decoder variants of Transformers are also called sequence-tosequence models. The exact details of pre-training objective vary from model to model. For example, FLAN-T5 is trained using span corruption. In span corruption, a part of the input sequence is masked and replaced by a sentinel token. These sentinel tokens are special tokens added to the vocabulary that to do not correspond to any actual word from the dataset. The decoder then has to reconstruct the sentence autoregressively. The output is the sentinel token followed by the predicted tokens.</p> <p><img alt="Encoder-decoder" src="../../assets/images/encoder_decoder.png"/></p> <p>We can use such models for tasks such as translation, summarization and question answering. They are most useful where the input and output both are bodies of text. Examples: FLAN-T5, BART.</p> <h4 id="attention-scores">Attention Scores<a class="headerlink" href="#attention-scores" title="Permanent link">‚öë</a></h4> <p>The attention calculation computes the similarity matrix between queries and keys <span class="arithmatex">\(QK^{T}\)</span> then uses a softmax function to convert the scores into a probability distribution, which is multiplied by the values embeddings <span class="arithmatex">\(V\)</span> to produce the output vector <span class="arithmatex">\(Z\)</span></p> <p>Before applying the softmax function, <span class="arithmatex">\(QK^{T}\)</span> is divided by <span class="arithmatex">\(\sqrt{d_{k}}\)</span> (the square root of the dimension of <span class="arithmatex">\(K\)</span>) in order to avoid tiny gradients at extreme values.</p> <p>Attention scores describes the mathematical definition of attention. Attenntion mechanisms are about how mathematical operations are applied to different set of queries, kyes and values.</p> <p>This creates the following complete formula for scaled multiplicative attention:</p> <div class="arithmatex">\[ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \]</div> <h5 id="types">Types<a class="headerlink" href="#types" title="Permanent link">‚öë</a></h5> <h6 id="multiplicative-attention-dot-product-attention">Multiplicative Attention (Dot-Product Attention)<a class="headerlink" href="#multiplicative-attention-dot-product-attention" title="Permanent link">‚öë</a></h6> <p>Multiplicative attention, also known as dot-product attention, calculates the attention scores by performing a dot product between the query and the key. It is a simple and efficient way to measure the similarity between the query and the key.</p> <p><span class="arithmatex">\(Attention(Q, K, V) = softmax(QK^{T})V\)</span></p> <p>In this formula, <span class="arithmatex">\(Q\)</span> represents the query matrix, <span class="arithmatex">\(K\)</span> the key matrix, and <span class="arithmatex">\(V\)</span> the value matrix. The attention scores are obtained by first calculating the dot product between <span class="arithmatex">\(Q\)</span> and <span class="arithmatex">\(K^{T}\)</span> (the transpose of <span class="arithmatex">\(K\)</span>), followed by applying the softmax function to ensure the scores are normalized to sum up to 1.</p> <h6 id="additive-attention">Additive Attention<a class="headerlink" href="#additive-attention" title="Permanent link">‚öë</a></h6> <p>Additive attention, also known as content-based attention, computes the attention scores by adding the query and the key together, usually followed by a non-linear activation function such as tanh, and then projecting the result through a learnable weight matrix to produce the scores.</p> <p><span class="arithmatex">\(Attention(Q, K, V) = softmax(W[(Q + K)^{T}])V\)</span></p> <p>Here, <span class="arithmatex">\(W\)</span> is a weight matrix that is learned during training. The addition of <span class="arithmatex">\(Q\)</span> and <span class="arithmatex">\(K\)</span> allows for a more flexible interaction between the query and the keys, potentially capturing more complex dependencies.</p> <h6 id="general-attention">General Attention<a class="headerlink" href="#general-attention" title="Permanent link">‚öë</a></h6> <p>General attention is a variant of multiplicative attention where the similarity between the query and the key is calculated using a learnable weight matrix. This allows the model to learn an optimal way of computing attention scores.</p> <p><span class="arithmatex">\(Attention(Q, K, V) = softmax(QW_kK^{T})V\)</span></p> <p>In this case, <span class="arithmatex">\(W_{k}\)</span> is a learnable weight matrix that transforms the key before computing the dot product with the query. This adds an additional level of flexibility compared to the standard dot-product attention, as the model can learn the most effective way to compare queries and keys.</p> <p>Each of these attention mechanisms provides a different way to calculate how much focus or "attention" should be given to different parts of the input when performing a task, allowing models to dynamically weigh the importance of different elements in the data.</p> <h4 id="attention-mechanisms">Attention Mechanisms<a class="headerlink" href="#attention-mechanisms" title="Permanent link">‚öë</a></h4> <p>Attention scores describes the mathematical definition of attention. Attenntion mechanisms are about how mathematical operations are applied to different set of queries, kyes and values.</p> <p>when some part of a neural network applies an attention score or mechanism to some information, you might think that the standard phrasing would be "A pays attention to B". Instead, we typically say that "A attends to B". This standard terminology is more concise and less anthropomorphizing.</p> <h5 id="self-attention">Self-Attention<a class="headerlink" href="#self-attention" title="Permanent link">‚öë</a></h5> <p>This was the original attention mechanism described by Vaswani et al. (2017).</p> <div class="arithmatex">\[Q = K = V\]</div> <p>Each position in the sequence attends to all positions in the same sequence.</p> <p>Self-attention has an interaction distance of <span class="arithmatex">\(O(1)\)</span>, which is a major improvement over the <span class="arithmatex">\(O(n)\)</span> interaction distance of an RNN. The drawback is that it has <span class="arithmatex">\(O(n^2)\)</span> computation.</p> <h5 id="multi-head-attention">Multi-Head Attention<a class="headerlink" href="#multi-head-attention" title="Permanent link">‚öë</a></h5> <p>Multiple Q, K, V heads</p> <p>Each head has its own set of weights, and attention is distributed, with each head focusing on a different specialized feature of the input.</p> <h5 id="multi-query-attention">Multi-Query Attention<a class="headerlink" href="#multi-query-attention" title="Permanent link">‚öë</a></h5> <p>Multiple Q heads, 1 K, V head</p> <p>Each query is distinct and shares the same key and value. Compared to multi-head attention, it is more efficient and can significantly increase the training batch size through parameter sharing.</p> <p>Billion-parameter LLMs like Falcon and LLaMA 2 use multi-query attention.</p> <h5 id="cross-attention">Cross-Attention<a class="headerlink" href="#cross-attention" title="Permanent link">‚öë</a></h5> <p>Q ‚â† K, V</p> <p>Used to "cross-reference" between different modalities or sequences. This mechanism is especially useful for tasks where different data types interact, e.g., image captioning.</p> <h4 id="attention-problems-and-solutions">Attention problems and solutions<a class="headerlink" href="#attention-problems-and-solutions" title="Permanent link">‚öë</a></h4> <p>If self-attention is so powerful, can it replace RNNs altogether? Vaswani et al. (2017) argue that it can, with the right solutions in place to address its limitations.</p> <ul> <li> <p>Problem: lack of input order</p> <ul> <li>As previously described with ELMo, context is important for understanding the meaning of words.</li> <li>Self-attention doesn't understand this by default, so we add positional encodings as part of the input embeddings.</li> </ul> </li> <li> <p>Problem: no nonlinearity between repeated self-attention layers</p> <ul> <li>The reason we typically use an activation function like ReLU in a neural network layer, rather than just a linear output, is to enable the model to capture more complexity. Linear outputs can be reduced to a simple <span class="arithmatex">\((y = mx + b)\)</span> style formula.</li> <li>Self-attention layers don't have this nonlinearity by default, so we add a feed-forward network for each processed token afterward.</li> </ul> </li> <li> <p>Problem: "cheating" when predicting a sequence</p> <ul> <li>The goal of a deep learning model is to be able to predict some unknown information given some known information. If all of the information is known, the model can't learn the relationships properly.</li> <li>By default, self-attention can look at all of the data, including the "future" that it is trying to predict. To prevent this, we mask attention on future words during decoding.</li> </ul> </li> <li> <p><a href="https://www.comet.com/site/blog/explainable-ai-for-transformers/">Explainable AI: Visualizing Attention in Transformers</a></p> </li> </ul> <h4 id="positional-embeddings">Positional Embeddings<a class="headerlink" href="#positional-embeddings" title="Permanent link">‚öë</a></h4> <p>Because attention layers don't understand order by default, we encode the ordering of the tokens in an embedding. Algorithms for positional embeddings include:</p> <ul> <li> <p>Absolute positional embeddings:</p> <ul> <li>Sinusoidal (original)</li> <li>Learned (BERT, GPT)</li> </ul> </li> <li> <p>Relative positional embeddings</p> <ul> <li>TransformerXL</li> </ul> </li> <li> <p>Rotary positional embeddings</p> </li> </ul> <h4 id="residual-connections">Residual Connections<a class="headerlink" href="#residual-connections" title="Permanent link">‚öë</a></h4> <p>A residual connection is a type of skipped layer, designed to address the vanishing gradient problem. It originated from the 2015 ResNets paper by He et al. and was originally used for computer vision tasks.</p> <h4 id="layer-normalization">Layer Normalization<a class="headerlink" href="#layer-normalization" title="Permanent link">‚öë</a></h4> <p>Layer normalization is the process of subtracting the mean and dividing by the standard deviation of the inputs for each sample. This stabilizes and speeds up the model training.</p> <p>Similar to the scaled attention score described previously, this step is helpful because of how it impacts the gradients that neural networks use for backpropagation.</p> <h3 id="prompting-and-prompt-engineering">Prompting and Prompt Engineering<a class="headerlink" href="#prompting-and-prompt-engineering" title="Permanent link">‚öë</a></h3> <p>We define a prompt as:</p> <ul> <li><span class="arithmatex">\(X \rightarrow\)</span> The user prompt, is like the features in ML.</li> <li><span class="arithmatex">\(Y \rightarrow\)</span> Masked (Next token)/Response(Next Token) Like Y label in ML.</li> <li><span class="arithmatex">\(\theta \rightarrow\)</span> Model weights</li> </ul> <h4 id="prompting">Prompting<a class="headerlink" href="#prompting" title="Permanent link">‚öë</a></h4> <p>The text that is fed to LLMs as input is called the prompt and the act of providing the input is called prompting.</p> <h4 id="prompt-engineering">Prompt Engineering<a class="headerlink" href="#prompt-engineering" title="Permanent link">‚öë</a></h4> <p>The process of tweaking the prompt provided to an LLM so that it gives the best possible result is called prompt engineering. Some common techniques are given below.</p> <h4 id="in-context-learning-icl">In-Context Learning (ICL)<a class="headerlink" href="#in-context-learning-icl" title="Permanent link">‚öë</a></h4> <p>In ICL, we add examples of the task we are doing in the prompt. This adds more context for the model in the prompt, allowing the model to ‚Äúlearn‚Äù more about the task detailed in the prompt.</p> <h5 id="zero-shot-inference">Zero-Shot Inference<a class="headerlink" href="#zero-shot-inference" title="Permanent link">‚öë</a></h5> <p>For example, we might be doing semantic classification using our LLM. In that case, a prompt could be:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a>Classify<span class="w"> </span>this<span class="w"> </span>review:<span class="w"> </span>I<span class="w"> </span>loved<span class="w"> </span>this<span class="w"> </span>movie!
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>Sentiment:
</span></code></pre></div> <p>This prompt works well with large LLMs but smaller LLMs might fail to follow the instruction due to their size and fewer number of features. This is also called zero-shot inference since our prompt has zero examples regarding what the model is expected to output.</p> <h5 id="few-shot-inference">Few-Shot Inference<a class="headerlink" href="#few-shot-inference" title="Permanent link">‚öë</a></h5> <p>This is where ICL comes into play. By adding examples to the prompt, even a smaller LLM might be able to follow the instruction and figure out the correct output. An example of such a prompt is shown below. This is also called one-shot inference since we are providing a single example in the prompt:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a>Classify<span class="w"> </span>this<span class="w"> </span>review:<span class="w"> </span>I<span class="w"> </span>loved<span class="w"> </span>this<span class="w"> </span>movie!
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>Sentiment:<span class="w"> </span>Positive
</span><span id="__span-1-3"><a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a>Classify<span class="w"> </span>this<span class="w"> </span>review:<span class="w"> </span>I<span class="w"> </span>don‚Äôt<span class="w"> </span>like<span class="w"> </span>this<span class="w"> </span>chair.
</span><span id="__span-1-4"><a href="#__codelineno-1-4" id="__codelineno-1-4" name="__codelineno-1-4"></a>Sentiment:
</span></code></pre></div> <p>Here, we first provide an example to the model and then ask it to figure out the output for the I don‚Äôt like this chair review. Sometimes, a single example won‚Äôt be enough for the model, for example when the model is even smaller. We‚Äôd then add multiple examples in the prompt. This is called few-shot inference.</p> <p>In other words:</p> <ul> <li>Larger models are good at zero-shot inference.</li> <li>For smaller models, we might need to add examples to the prompt, for few-shot inference.</li> </ul> <h4 id="inference-configuration-parameters">Inference Configuration Parameters<a class="headerlink" href="#inference-configuration-parameters" title="Permanent link">‚öë</a></h4> <ul> <li>Max New Tokens: This is used to limit the maximum number of new tokens that should be generated by the model in its output. The model might output fewer tokens (for example,it predicts <eos> before reaching the limit) but not more than this number.</eos></li> <li>Greedy vs Random Sampling: Some models also give the user control over whether the model should use greedy or random sampling.</li> <li> <p>Sample Top-K and Sample Top-P: Sample Top-K and Sample Top-P are used to limit the random sampling of a model. A top-K value instructs the model to only consider K words with the highest probabilities in its random sampling. Consider the following softmax output:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a>Probability<span class="w"> </span>Word
</span><span id="__span-2-2"><a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="m">0</span>.20<span class="w"> </span>cake
</span><span id="__span-2-3"><a href="#__codelineno-2-3" id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="m">0</span>.10<span class="w"> </span>donut
</span><span id="__span-2-4"><a href="#__codelineno-2-4" id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="m">0</span>.02<span class="w"> </span>banana
</span><span id="__span-2-5"><a href="#__codelineno-2-5" id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="m">0</span>.01<span class="w"> </span>apple
</span></code></pre></div> <p>If K = 3, the model will select one of cake, donut or banana. This allows the model to have variability while preventing the selection of some highly improbable words in its output. The top-P value instructs the model to only consider words with the highest probabilities such that their cumulative probability, p1 + p2 + ¬∑ ¬∑ ¬∑ + pK ‚â§ P. For example, considering the above output, if we set P = 0.30, the model will only consider the words cake and donut since 0.20 + 0.10 ‚â§ 0.30.</p> </li> <li> <p>Temperature: Temperature is also another parameter used to control random sampling. It determines the shape of the probability distribution that the model calculates for the next word. Intuitively, a higher temperature increases the randomness of the model while a lower temperature decreases the randomness of the model. This temperature is passed as a scaling factor to the final softmax layer of the decoder. If we pick a cooler temperature (T &lt; 1), the probability distribution is strongly peaked. In other words, one (or a few more) words have very high probabilities while the rest of the words have very low probabilities:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a>Probability<span class="w"> </span>Word
</span><span id="__span-3-2"><a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="m">0</span>.001<span class="w"> </span>apple
</span><span id="__span-3-3"><a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="m">0</span>.002<span class="w"> </span>banana
</span><span id="__span-3-4"><a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="m">0</span>.400<span class="w"> </span>cake
</span><span id="__span-3-5"><a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="m">0</span>.012<span class="w"> </span>donut
</span><span id="__span-3-6"><a href="#__codelineno-3-6" id="__codelineno-3-6" name="__codelineno-3-6"></a>.<span class="w"> </span>.<span class="w"> </span>.<span class="w"> </span>.<span class="w"> </span>.<span class="w"> </span>.
</span></code></pre></div> <p>Notice how cake has a 40% chance of being picked while other words have very small chances of being picked. The resulting text will be less random. On the other hand, if we pick a warmer temperature (T &gt; 1), the probability distribution is broader, flatter and more evenly spread over the tokens:</p> <div class="language-text highlight"><pre><span></span><code>```bash
Probability Word
0.040 apple
0.080 banana
0.150 cake
0.120 donut
. . . . . .
```
</code></pre></div> <p>Notice how none of the words have a clear advantage over the other words. The model generates text with a higher amount of randomness and has more variability in its output. Clearly, when T = 1, the model uses the softmax output as is for random sampling.</p> <p>You can find more information in how the different decoders works <a href="https://huggingface.co/blog/how-to-generate">Link</a></p> </li> </ul> <h4 id="virtuous-feedback-loops">Virtuous Feedback Loops<a class="headerlink" href="#virtuous-feedback-loops" title="Permanent link">‚öë</a></h4> <p>Setting aside the model weights, we can see how the LLM can enable virtuous feedback loops (as opposed to the vicious feedback loops seen earlier) by considering how the LLM can aid in the generation of helpful prompt context.</p> <p>Recall for the prediction of <span class="arithmatex">\(Y\)</span>, given <span class="arithmatex">\(X\)</span>, <span class="arithmatex">\(P(Y|X)\)</span>, that the LLM generates each token in Y, one at a time, appending the previously generated token to <span class="arithmatex">\(X\)</span>. In the case of a prompt, <span class="arithmatex">\(n\)</span> tokens long, and a complete prompt + LLM response <span class="arithmatex">\(k\)</span> tokens long, then the tokens in <span class="arithmatex">\(X\)</span> from <span class="arithmatex">\(n+1\)</span> to <span class="arithmatex">\(k-1\)</span> came from the LLM. This can be represented mathematically below:</p> <p><span class="arithmatex">\(P(Y_{n+1} | X_{0,1..n}) \rightarrow\)</span> <span class="arithmatex">\(P(Y_{n+2} | X_{0,1..n+1}) \rightarrow\)</span> <span class="arithmatex">\(P(Y_{n+3} | X_{0,1..n+2}) \rightarrow\)</span> <span class="arithmatex">\(\dots \rightarrow P(Y_k | X_{0,1..k-1})\)</span></p> <p>Techniques that guide the LLM toward generating assistive tokens at the start of the LLM response can aid in answering a question at the end of the prompt, effectively helping the LLM write its own features.</p> <p>An example of a virtuous feedback loop is provided by ‚ÄúChain of Thought‚Äù</p> <h5 id="workflow-to-try-prompts">Workflow to try prompts<a class="headerlink" href="#workflow-to-try-prompts" title="Permanent link">‚öë</a></h5> <ul> <li><a href="../tutorials/try_promt_techniques/">Notebook</a></li> </ul> <h3 id="data">Data<a class="headerlink" href="#data" title="Permanent link">‚öë</a></h3> <h4 id="most-common-sources">Most common sources<a class="headerlink" href="#most-common-sources" title="Permanent link">‚öë</a></h4> <ul> <li><a href="https://commoncrawl.org/">Common crawl</a></li> <li><a href="https://www.githubarchive.org/">Github dataset</a></li> <li><a href="https://dumps.wikimedia.org/">Wikipedia</a></li> <li><a href="https://www.gutenberg.org/">Gutenberg</a></li> <li><a href="https://rajpurkar.github.io/SQuAD-explorer/">Stanford Question Answering Dataset</a></li> <li><a href="https://hotpotqa.github.io/">HotPotQA</a></li> <li><a href="https://github.com/megagonlabs/SubjQA">SubjQA</a></li> </ul> <h4 id="generating-traing-data-with-llms">Generating traing data with LLMs<a class="headerlink" href="#generating-traing-data-with-llms" title="Permanent link">‚öë</a></h4> <p>LLMs can be used for the generation of training data along multiple dimensions, including:</p> <ul> <li> <p>Generation of responses from pre-existing queries_</p> <p>Enabling instruction fine-tuning dataset pairs:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="o">{</span><span class="s2">"prompt"</span>:<span class="w"> </span>&lt;existing_instruction&gt;,<span class="w"> </span><span class="s2">"completion"</span>:<span class="w"> </span>&lt;LLM_generated_response&gt;<span class="o">}</span>
</span></code></pre></div> <p>This is probably the most straightforward usage of LLMs for synthetic dataset generation. Ensure LLM's license supports such usage.</p> </li> <li> <p>Generation of instructions from pre-existing documents. Enabling instruction fine-tuning dataset pairs:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="o">{</span><span class="s2">"prompt"</span>:<span class="w"> </span>&lt;LLM_generated_instruction&gt;,<span class="w"> </span><span class="s2">"completion"</span>:<span class="w"> </span>&lt;existing_document_chunk&gt;<span class="o">}</span>
</span></code></pre></div> <p>This method, known as back-translation from the development of translation systems for low-resource languages, has been given this modern spin in <a href="https://arxiv.org/abs/2308.06259">"Self-Alignment with Instruction Backtranslation"</a></p> </li> <li> <p>Generation of preference data from existing prompt/response LLM pairs: For example, the comparison of:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="o">{{</span><span class="s2">"prompt"</span>:<span class="w"> </span>&lt;prompt_0&gt;,<span class="w"> </span><span class="s2">"completion"</span>:<span class="w"> </span>&lt;completion_a&gt;<span class="o">}</span>,<span class="w"> </span><span class="s2">"pref"</span>:<span class="w"> </span>LLM_generated_preference_1<span class="o">}}</span>
</span></code></pre></div> <p>vs.</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a href="#__codelineno-8-1" id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="o">{{</span><span class="s2">"prompt"</span>:<span class="w"> </span>&lt;prompt_0&gt;,<span class="w"> </span><span class="s2">"completion"</span>:<span class="w"> </span>&lt;completion_a&gt;<span class="o">}</span>,<span class="w"> </span><span class="s2">"pref"</span>:<span class="w"> </span>LLM_generated_preference_-1<span class="o">}}</span>
</span></code></pre></div> <p>This can be used for Reinforcement Learning from Human Feedback (despite the feedback being non-human in this case), as explored more in <a href="https://arxiv.org/abs/2212.08073">"Constitutional AI: Harmlessness from AI Feedback"</a>.</p> </li> </ul> <h3 id="resources">Resources<a class="headerlink" href="#resources" title="Permanent link">‚öë</a></h3> <ul> <li><a href="https://www.comet.com/site/blog/explainable-ai-for-transformers/">Explainable AI: Visualizing Attention in Transformers</a></li> <li><a href="https://jalammar.github.io/illustrated-transformer/">Illustrated Transformer</a> (a wonderful introduction) and the</li> <li><a href="https://nlp.seas.harvard.edu/annotated-transformer/">Annotated Transformer</a> (with a line-by-line implementation in Python).</li> <li><a href="https://huggingface.co/blog/how-to-generate">How decoder works</a></li> </ul> <hr/> <div class="md-source-file"> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class="timeago" datetime="2024-10-23T19:24:07+00:00" locale="en"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-10-23</span> <br/> Created: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class="timeago" datetime="2024-10-23T19:24:07+00:00" locale="en"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-10-23</span> </small> </div> <form class="md-feedback" hidden="" name="feedback"> <fieldset> <legend class="md-feedback__title"> Was this page helpful? </legend> <div class="md-feedback__inner"> <div class="md-feedback__list"> <button class="md-feedback__icon md-icon" data-md-value="1" title="This page was helpful" type="submit"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"></path></svg> </button> <button class="md-feedback__icon md-icon" data-md-value="0" title="This page could be improved" type="submit"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"></path></svg> </button> </div> <div class="md-feedback__note"> <div data-md-value="1" hidden=""> Thanks for your feedback! </div> <div data-md-value="0" hidden=""> Thanks for your feedback! Help us improve this page by using our <a href="..." rel="noopener" target="_blank">feedback form</a>. </div> </div> </div> </fieldset> </form> </article> </div> </div> <button class="md-top md-icon" data-md-component="top" hidden="" type="button"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> Back to top </button> </main> <footer class="md-footer"> <nav aria-label="Footer" class="md-footer__inner md-grid"> <a aria-label="Previous: Bigquery" class="md-footer__link md-footer__link--prev" href="../../cloud/google/Bigquery/" rel="prev"> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </div> <div class="md-footer__title"> <span class="md-footer__direction"> Previous </span> <div class="md-ellipsis"> Bigquery </div> </div> </a> <a aria-label="Next: NLP" class="md-footer__link md-footer__link--next" href="../nlp/Natural%20Language%20Processing/" rel="next"> <div class="md-footer__title"> <span class="md-footer__direction"> Next </span> <div class="md-ellipsis"> NLP </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-copyright"> Made with <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank"> Material for MkDocs </a> </div> <div class="md-social"> <a class="md-social__link" href="https://github.com/diefergil" rel="noopener" target="_blank" title="github.com"> <svg viewbox="0 0 480 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg> </a> <a class="md-social__link" href="https://diefergil.github.io/personal-notes/newsletter/0_newsletter_index" rel="noopener" target="_blank" title="diefergil.github.io"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M0 64c0-17.7 14.3-32 32-32 229.8 0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7 0 64zm0 352a64 64 0 1 1 128 0 64 64 0 1 1-128 0zm32-256c159.1 0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7 0-32-14.3-32-32s14.3-32 32-32z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class="md-dialog" data-md-component="dialog"> <div class="md-dialog__inner md-typeset"></div> </div> <div class="md-consent" data-md-component="consent" hidden="" id="__consent"> <div class="md-consent__overlay"></div> <aside class="md-consent__inner"> <form class="md-consent__form md-grid md-typeset" name="consent"> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class="md-toggle" id="__settings" type="checkbox"/> <div class="md-consent__settings"> <ul class="task-list"> <li class="task-list-item"> <label class="task-list-control"> <input checked="" name="analytics" type="checkbox"/> <span class="task-list-indicator"></span> Google Analytics </label> </li> <li class="task-list-item"> <label class="task-list-control"> <input checked="" name="github" type="checkbox"/> <span class="task-list-indicator"></span> GitHub </label> </li> </ul> </div> <div class="md-consent__controls"> <button class="md-button md-button--primary">Accept</button> <label class="md-button" for="__settings">Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script> <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.footer", "navigation.instant", "navigation.top", "content.code.annotate", "search.suggest", "search.highlight", "content.code.copy", "content.code.select"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script> <script src="../../js/timeago.min.js"></script> <script src="../../js/timeago_mkdocs_material.js"></script> <script src="../../optionalConfig.js"></script> <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script> <script src="../../extra-loader.js"></script> <script src="../../javascripts/mathjax.js"></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </body> </html>
<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="My personal notes" name="description"/><meta content="Diego" name="author"/><link href="https://diefergil.github.io/personal-notes/generative_ai/Fine%20Tuning/" rel="canonical"/><link href="../prompting/" rel="prev"/><link href="../Reinforcement%20Learning%20From%20Human%20Feedback/" rel="next"/><link href="../../assets/images/favicon.png" rel="icon"/><meta content="mkdocs-1.4.3, mkdocs-material-9.1.20" name="generator"/><title>Instruction Fine-Tuning - My personal notes</title><link href="../../assets/stylesheets/main.eebd395e.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/palette.ecc896b0.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href="../../css/timeago.css" rel="stylesheet"/><link href="../../stylesheets/extra.css" rel="stylesheet"/><link href="../../stylesheets/links.css" rel="stylesheet"/><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-6S6TNHYVRT"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-6S6TNHYVRT",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-6S6TNHYVRT",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script></head> <body data-md-color-accent="light-blue" data-md-color-primary="blue-grey" data-md-color-scheme="default" dir="ltr"> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" for="__drawer"></label> <div data-md-component="skip"> <a class="md-skip" href="#lora"> Skip to content </a> </div> <div data-md-component="announce"> <aside class="md-banner"> <div class="md-banner__inner md-grid md-typeset"> For updates subscribe to the <a href="https://diefergil.github.io/personal-notes/newsletter/0_newsletter_index/"><strong>RSS feed</strong></a> <img height="15" src="/personal-notes/img/orange_logo.png" width="15"/> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component="header"> <nav aria-label="Header" class="md-header__inner md-grid"> <a aria-label="My personal notes" class="md-header__button md-logo" data-md-component="logo" href="../.." title="My personal notes"> <img alt="logo" src="../../img/logo.bmp"/> </a> <label class="md-header__button md-icon" for="__drawer"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class="md-header__title" data-md-component="header-title"> <div class="md-header__ellipsis"> <div class="md-header__topic"> <span class="md-ellipsis"> My personal notes </span> </div> <div class="md-header__topic" data-md-component="header-topic"> <span class="md-ellipsis"> Instruction Fine-Tuning </span> </div> </div> </div> <form class="md-header__option" data-md-component="palette"> <input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="light-blue" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="blue-grey" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"></path></svg> </label> <input aria-label="Switch to light mode" class="md-option" data-md-color-accent="light-blue" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="blue-grey" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"></path></svg> </label> </form> <label class="md-header__button md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/> <label class="md-search__icon md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label="Search" class="md-search__options"> <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> <div class="md-search__suggest" data-md-component="search-suggest"></div> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="search-result"> <div class="md-search-result__meta"> Initializing search </div> <ol class="md-search-result__list" role="presentation"></ol> </div> </div> </div> </div> </div> <div class="md-header__source"> <a class="md-source" data-md-component="source" href="https://github.com/diefergil/personal-notes" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> diefergil/personal-notes </div> </a> </div> </nav> </header> <div class="md-container" data-md-component="container"> <main class="md-main" data-md-component="main"> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title" for="__drawer"> <a aria-label="My personal notes" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="My personal notes"> <img alt="logo" src="../../img/logo.bmp"/> </a> My personal notes </label> <div class="md-nav__source"> <a class="md-source" data-md-component="source" href="https://github.com/diefergil/personal-notes" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> diefergil/personal-notes </div> </a> </div> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.."> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/> <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0"> Cloud <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_2"> <span class="md-nav__icon md-icon"></span> Cloud </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_2_1" type="checkbox"/> <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0"> AWS <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_2_1_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_2_1"> <span class="md-nav__icon md-icon"></span> AWS </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/app_runner/"> App Runner </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/batch/"> Batch </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/lambda/"> Lambda functions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/aws/steps/"> Steps </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_2_2" type="checkbox"/> <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0"> Google Cloud <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_2_2_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_2_2"> <span class="md-nav__icon md-icon"></span> Google Cloud </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/gcloud/"> gcloud CLI </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/app_engine/"> App Engine </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/cloud_functions/"> Cloud Functions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/cloud_run/"> Cloud Run </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../cloud/google/Bigquery/"> Bigquery </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/> <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0"> Generative AI <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_3"> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../introduction/"> Introduction </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../nlp/Natural%20Language%20Processing/"> NLP </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/> <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0"> Adapting foundational models <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="true" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_3"> <span class="md-nav__icon md-icon"></span> Adapting foundational models </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../prompting/"> Prompting </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> Instruction Fine-Tuning <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href="./"> Instruction Fine-Tuning </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#lora"> Lora </a> <nav aria-label="Lora" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#multiple-tasks"> Multiple Tasks </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#choosing-the-rank-r"> Choosing The Rank r </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#hugging-face-peft"> Hugging Face PEFT </a> <nav aria-label="Hugging Face PEFT" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#concepts"> Concepts </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-with-peft"> Training with PEFT </a> <nav aria-label="Training with PEFT" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#creating-a-peft-config"> Creating a PEFT Config </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#converting-a-transformers-model-into-a-peft-model"> Converting a Transformers Model into a PEFT Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-with-a-peft-model"> Training with a PEFT Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#checking-trainable-parameters-of-a-peft-model"> Checking Trainable Parameters of a PEFT Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#saving-a-trained-peft-model"> Saving a Trained PEFT Model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#inference-with-peft"> Inference with PEFT </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#generating-text-from-a-peft-model"> Generating Text from a PEFT Model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#lora-resources"> Lora Resources </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#peft-methods-in-general"> PEFT Methods in General </a> <nav aria-label="PEFT Methods in General" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#selective"> Selective </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#reparameterization"> Reparameterization </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#additive"> Additive </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#soft-prompts"> Soft Prompts </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#hugging-face-peft-library"> Hugging Face PEFT Library </a> <nav aria-label="Hugging Face PEFT Library" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#key-concepts"> Key Concepts </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-peft"> Training PEFT </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#instruction-fine-tuning"> Instruction Fine-Tuning </a> <nav aria-label="Instruction Fine-Tuning" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#limitations-of-icl"> Limitations of ICL </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#common-steps-involved-in-instruction-fine-tuning"> Common Steps Involved in Instruction Fine-Tuning </a> <nav aria-label="Common Steps Involved in Instruction Fine-Tuning" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#prepare-the-dataset"> Prepare the Dataset </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#split-dataset"> Split Dataset </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training"> Training </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#fine-tuning-on-a-single-task"> Fine-Tuning On a Single Task </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#catastrophic-forgetting"> Catastrophic Forgetting </a> <nav aria-label="Catastrophic Forgetting" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#avoiding-catastrophic-forgetting"> Avoiding Catastrophic Forgetting </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#fine-tuning-on-multiple-tasks"> Fine-Tuning On Multiple Tasks </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#case-study-flan"> Case Study - FLAN </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#instruction-fine-tuning-resources"> Instruction Fine tuning Resources </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Reinforcement%20Learning%20From%20Human%20Feedback/"> Reinforcement Learning From Human Feedback </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../probing/"> Probing </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Evaluate%20LLMs/"> Evaluation </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../Deploy%20LLMS/"> Deployment </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_6" type="checkbox"/> <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0"> HuggingFace <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_6_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_6"> <span class="md-nav__icon md-icon"></span> HuggingFace </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../huggingface/"> Overview </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/hugginface_intro/"> Hugginface Intro </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/hugging-face-tokenizer/"> Using Hugging Face Tokenizers </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/diffusers/"> Diffusion models and the library from 🤗 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_7" type="checkbox"/> <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0"> Embeddings <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_7_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_7"> <span class="md-nav__icon md-icon"></span> Embeddings </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/lance_db/"> Vector Database Basics </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/lance_db_multimodal/"> Multimodal Search </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8" type="checkbox"/> <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0"> Tutorials <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_8_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_3_8"> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/pytorch_intro/"> Pytorch </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8_2" type="checkbox"/> <div class="md-nav__link md-nav__link--index"> <a href="../tutorials/try_promt_techniques/">Promting techninques review</a> <label for="__nav_3_8_2"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="false" aria-labelledby="__nav_3_8_2_label" class="md-nav" data-md-level="3"> <label class="md-nav__title" for="__nav_3_8_2"> <span class="md-nav__icon md-icon"></span> Promting techninques review </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/Building_QA_Datasets/"> Building Question Answering Datasets </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/wikipedia_qa/"> Wikipedia QA Opean AI example </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/example_ReAcT_prompt/"> React promt example </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/openai_functions/"> Open AI call function </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain_examples/"> Langchain introduction </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8_6" type="checkbox"/> <label class="md-nav__link" for="__nav_3_8_6" id="__nav_3_8_6_label" tabindex="0"> Transfer Learning <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_3_8_6_label" class="md-nav" data-md-level="3"> <label class="md-nav__title" for="__nav_3_8_6"> <span class="md-nav__icon md-icon"></span> Transfer Learning </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/transfer-learning-mobilenet/"> Exercise: Transfer learning using MobileNetV3 </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/train_gans/"> Generative Adversarial Network: training </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/training_DDPM/"> Train a Denoising Diffusion Probabilistic Model from scratch </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_3_8_9" type="checkbox"/> <div class="md-nav__link md-nav__link--index"> <a href="../tutorials/langchain/snnipets/">Langchain</a> <label for="__nav_3_8_9"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="false" aria-labelledby="__nav_3_8_9_label" class="md-nav" data-md-level="3"> <label class="md-nav__title" for="__nav_3_8_9"> <span class="md-nav__icon md-icon"></span> Langchain </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/Lesson_2_Student/"> Lesson 2 : LangGraph Components </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/Lesson_4_Student/"> Lesson 4: Persistence and Streaming </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/Lesson_5_Student/"> Lesson 5: Human in the Loop </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/agents/helper/"> Helper </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/functions/L2-lcel-student/"> LangChain Expression Language (LCEL) </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/functions/L5-tools-routing-apis-student/"> Tools and Routing </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tutorials/langchain/functions/L6-functional_conversation-student/"> Conversational agent </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/> <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0"> Mlops <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_4"> <span class="md-nav__icon md-icon"></span> Mlops </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/mlops_intro/"> Introduction </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/continous_delivery/"> Continous integration </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_4_3" type="checkbox"/> <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0"> Tools <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_4_3_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_4_3"> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/tools/Docker/"> Docker </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/tools/github_actions/"> Github actions </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../mlops/tools/makefile/"> Makefile </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5" type="checkbox"/> <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0"> Python <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_5"> <span class="md-nav__icon md-icon"></span> Python </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_1" type="checkbox"/> <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0"> API's <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_1_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_1"> <span class="md-nav__icon md-icon"></span> API's </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/apis/best_practices/"> Best practices </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/apis/fastapi/"> FastAPI </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/apis/flask/"> Flask </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_2" type="checkbox"/> <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0"> CLI's <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_2_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_2"> <span class="md-nav__icon md-icon"></span> CLI's </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/cli/argparse/"> Argparse </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/cli/click/"> Click </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_3" type="checkbox"/> <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0"> Environments <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_3_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_3"> <span class="md-nav__icon md-icon"></span> Environments </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/environments/"> Virtual environments </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_4" type="checkbox"/> <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0"> Packaging <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_4_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_4"> <span class="md-nav__icon md-icon"></span> Packaging </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/packaging/setuptools/"> Setuptools </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/packaging/Poetry/"> Poetry </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_5_5" type="checkbox"/> <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0"> Tests <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_5_5_label" class="md-nav" data-md-level="2"> <label class="md-nav__title" for="__nav_5_5"> <span class="md-nav__icon md-icon"></span> Tests </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../python/pytest/"> Pytests </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/> <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0"> Infrastructure <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="false" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_6"> <span class="md-nav__icon md-icon"></span> Infrastructure </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../IAC/Pulumi/"> Pulumi </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../IAC/Terraform/"> Terraform </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../about/"> About </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#lora"> Lora </a> <nav aria-label="Lora" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#multiple-tasks"> Multiple Tasks </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#choosing-the-rank-r"> Choosing The Rank r </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#hugging-face-peft"> Hugging Face PEFT </a> <nav aria-label="Hugging Face PEFT" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#concepts"> Concepts </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-with-peft"> Training with PEFT </a> <nav aria-label="Training with PEFT" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#creating-a-peft-config"> Creating a PEFT Config </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#converting-a-transformers-model-into-a-peft-model"> Converting a Transformers Model into a PEFT Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-with-a-peft-model"> Training with a PEFT Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#checking-trainable-parameters-of-a-peft-model"> Checking Trainable Parameters of a PEFT Model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#saving-a-trained-peft-model"> Saving a Trained PEFT Model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#inference-with-peft"> Inference with PEFT </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#generating-text-from-a-peft-model"> Generating Text from a PEFT Model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#lora-resources"> Lora Resources </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#peft-methods-in-general"> PEFT Methods in General </a> <nav aria-label="PEFT Methods in General" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#selective"> Selective </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#reparameterization"> Reparameterization </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#additive"> Additive </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#soft-prompts"> Soft Prompts </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#hugging-face-peft-library"> Hugging Face PEFT Library </a> <nav aria-label="Hugging Face PEFT Library" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#key-concepts"> Key Concepts </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-peft"> Training PEFT </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#instruction-fine-tuning"> Instruction Fine-Tuning </a> <nav aria-label="Instruction Fine-Tuning" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#limitations-of-icl"> Limitations of ICL </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#common-steps-involved-in-instruction-fine-tuning"> Common Steps Involved in Instruction Fine-Tuning </a> <nav aria-label="Common Steps Involved in Instruction Fine-Tuning" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#prepare-the-dataset"> Prepare the Dataset </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#split-dataset"> Split Dataset </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training"> Training </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#fine-tuning-on-a-single-task"> Fine-Tuning On a Single Task </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#catastrophic-forgetting"> Catastrophic Forgetting </a> <nav aria-label="Catastrophic Forgetting" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#avoiding-catastrophic-forgetting"> Avoiding Catastrophic Forgetting </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#fine-tuning-on-multiple-tasks"> Fine-Tuning On Multiple Tasks </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#case-study-flan"> Case Study - FLAN </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#instruction-fine-tuning-resources"> Instruction Fine tuning Resources </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-content" data-md-component="content"> <article class="md-content__inner md-typeset"> <!-- Google AdSense Code --> <script async="" crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4806129530093947"></script> <!-- End Google AdSense Code --> <nav class="md-tags"> <span class="md-tag">resource</span> </nav> <h1>Instruction Fine-Tuning</h1> <h2 id="lora">Lora<a class="headerlink" href="#lora" title="Permanent link">⚑</a></h2> <p>LoRA is a PEFT technique based on reparameterization. The encoder and decoder blocks of a Transformer consist of self-attention (in the form of Multi-Headed Attention) layers. Weights are applied to the input embedding vectors to obtain an attention map for the input prompt. In full fine-tuning, every weight in these layers is updated. In LoRA:</p> <ul> <li>All the model parameters are frozen.</li> <li>Two (smaller) rank decomposition matrices A and B are injected with the original weights. The dimensions of the matrices are such that their product has the same dimension as that of the original weight matrices.</li> <li> <p>The weights in the smaller matrices are trained via fine-tuning. For inference:</p> </li> <li> <p>We multiply the two low rank matrices to obtain B × A, which has the same dimensions as the frozen weights of the model.</p> </li> <li>We add B × A to the original frozen weights.</li> <li>The model weights are replaced with these new weights.</li> </ul> <p>We now have a fine-tuned model which can carry out the task(s) we have finetuned it for. Since the model has the same number of parameters as original, there is little to no impact on inference latency. Researchers have found that applying LoRA just to the self-attention layers is often enough to fine-tune for a task and achieve performance gains. However, in principle, we can use LoRA in other components such as the feed-forward layers. Since most of the parameters are the model are in the attention layers, we get the biggest savings when we apply LoRA in those layers.</p> <h3 id="multiple-tasks">Multiple Tasks<a class="headerlink" href="#multiple-tasks" title="Permanent link">⚑</a></h3> <p>LoRA also makes it easy to fine-tune a model for different tasks. We can train the model using the rank decomposition matrices for each of the tasks. This will give us a pair of A and B matrices for each task. During inference, we can swap out the matrices depending on the task we want the model to do and update the weights (by adding to the frozen weights).</p> <h3 id="choosing-the-rank-r">Choosing The Rank r<a class="headerlink" href="#choosing-the-rank-r" title="Permanent link">⚑</a></h3> <p>In general. The smaller the rank r, the smaller the number of trainable parameters and the bigger the savings on compute.</p> <p>According to the LoRA paper:</p> <ul> <li>Effectiveness of higher rank appears to plateau. That is, after a certain rank value, making it larger generally has no effect on performance.</li> <li>4 ≤ r ≤ 32 (in powers of 2) can provide a good trade-off between reducing trainable parameters and preserving performance.</li> <li>Relationship between rank and dataset size needs more research.</li> </ul> <h3 id="hugging-face-peft">Hugging Face PEFT<a class="headerlink" href="#hugging-face-peft" title="Permanent link">⚑</a></h3> <h4 id="concepts">Concepts<a class="headerlink" href="#concepts" title="Permanent link">⚑</a></h4> <div class="language-text highlight"><pre><span></span><code>1. Hugging Face PEFT allows you to fine-tune a model without having to fine-tune
all of its parameters.

2. Training a model using Hugging Face PEFT requires two additional steps beyond
traditional fine-tuning:
</code></pre></div> <p>Creating a PEFT config Converting the model into a PEFT model using the PEFT config Inference using a PEFT model is almost identical to inference using a non-PEFT model. The only difference is that it must be loaded as a PEFT model.</p> <h4 id="training-with-peft">Training with PEFT<a class="headerlink" href="#training-with-peft" title="Permanent link">⚑</a></h4> <h5 id="creating-a-peft-config">Creating a PEFT Config<a class="headerlink" href="#creating-a-peft-config" title="Permanent link">⚑</a></h5> <p>The PEFT config specifies the adapter configuration for your parameter-efficient fine-tuning process. The base class for this is a <code>PeftConfig</code>, but this example will use a <code>LoraConfig</code>, the subclass used for low rank adaptation (LoRA).</p> <p>A LoRA config can be instantiated like this:</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">LoraConfig</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="n">config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">()</span>
</span></code></pre></div> <p>Look at the LoRA adapter documentation for additional hyperparameters that can be specified by passing arguments to <code>LoraConfig()</code>. <a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora">The Hugging Face LoRA conceptual guide</a> also contains additional explanations.</p> <h5 id="converting-a-transformers-model-into-a-peft-model">Converting a Transformers Model into a PEFT Model<a class="headerlink" href="#converting-a-transformers-model-into-a-peft-model" title="Permanent link">⚑</a></h5> <p>Once you have a PEFT config object, you can load a Hugging Face transformers model as a PEFT model by first loading the pre-trained model as usual (here we load GPT-2):</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
</span></code></pre></div> <p>Then using <code>get_peft_model()</code> to get a trainable PEFT model (using the LoRA config instantiated previously):</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">get_peft_model</span>
</span><span id="__span-2-2"><a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="n">lora_model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
</span></code></pre></div> <h5 id="training-with-a-peft-model">Training with a PEFT Model<a class="headerlink" href="#training-with-a-peft-model" title="Permanent link">⚑</a></h5> <p>After calling <code>get_peft_model()</code>, you can then use the resulting <code>lora_model</code> in a training process of your choice (PyTorch training loop or Hugging Face <code>Trainer</code>).</p> <h5 id="checking-trainable-parameters-of-a-peft-model">Checking Trainable Parameters of a PEFT Model<a class="headerlink" href="#checking-trainable-parameters-of-a-peft-model" title="Permanent link">⚑</a></h5> <p>A helpful way to check the number of trainable parameters with the current config is the <code>print_trainable_parameters()</code> method:</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="n">lora_model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
</span></code></pre></div> <p>Which prints an output like this:</p> <div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a>trainable<span class="w"> </span>params:<span class="w"> </span><span class="m">294</span>,912<span class="w"> </span><span class="o">||</span><span class="w"> </span>all<span class="w"> </span>params:<span class="w"> </span><span class="m">124</span>,734,720<span class="w"> </span><span class="o">||</span><span class="w"> </span>trainable%:<span class="w"> </span><span class="m">0</span>.23643136409814364
</span></code></pre></div> <h5 id="saving-a-trained-peft-model">Saving a Trained PEFT Model<a class="headerlink" href="#saving-a-trained-peft-model" title="Permanent link">⚑</a></h5> <p>Once a PEFT model has been trained, the standard Hugging Face <code>save_pretrained()</code> method can be used to save the weights locally. For example:</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="n">lora_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">"gpt-lora"</span><span class="p">)</span>
</span></code></pre></div> <p>Note that this only saves the adapter weights and not the weights of the original Transformers model. Thus the size of the files created will be much smaller than you might expect.</p> <h4 id="inference-with-peft">Inference with PEFT<a class="headerlink" href="#inference-with-peft" title="Permanent link">⚑</a></h4> <p>Because you have only saved the adapter weights and not the full model weights, you can't use <code>from_pretrained()</code> with the regular Transformers class (e.g., <code>AutoModelForCausalLM</code>). Instead, you need to use the PEFT version (e.g., <code>AutoPeftModelForCausalLM</code>). For example:</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">AutoPeftModelForCausalLM</span>
</span><span id="__span-6-2"><a href="#__codelineno-6-2" id="__codelineno-6-2" name="__codelineno-6-2"></a><span class="n">lora_model</span> <span class="o">=</span> <span class="n">AutoPeftModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt-lora"</span><span class="p">)</span>
</span></code></pre></div> <p>After completing this step, you can proceed to use the model for inference.</p> <h4 id="generating-text-from-a-peft-model">Generating Text from a PEFT Model<a class="headerlink" href="#generating-text-from-a-peft-model" title="Permanent link">⚑</a></h4> <p>You may see examples from regular Transformer models where the input IDs are passed in as a positional argument (e.g., <code>model.generate(input_ids)</code>). For a PEFT model, they must be passed in as a keyword argument (e.g., <code>model.generate (input_ids=input_ids</code>)). For example:</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-7-2"><a href="#__codelineno-7-2" id="__codelineno-7-2" name="__codelineno-7-2"></a>
</span><span id="__span-7-3"><a href="#__codelineno-7-3" id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
</span><span id="__span-7-4"><a href="#__codelineno-7-4" id="__codelineno-7-4" name="__codelineno-7-4"></a><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"Hello, my name is "</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
</span><span id="__span-7-5"><a href="#__codelineno-7-5" id="__codelineno-7-5" name="__codelineno-7-5"></a><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">],</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span id="__span-7-6"><a href="#__codelineno-7-6" id="__codelineno-7-6" name="__codelineno-7-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span>
</span></code></pre></div> <h3 id="lora-resources">Lora Resources<a class="headerlink" href="#lora-resources" title="Permanent link">⚑</a></h3> <ul> <li><a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora">Lora intro</a></li> <li><a href="https://huggingface.co/docs/peft/package_reference/config">Hugging Face PEFT configuration</a></li> <li><a href="https://huggingface.co/docs/peft/package_reference/lora">Hugging Face LoRA adapter</a></li> <li><a href="https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">Hugging Face Models save_pretrained</a></li> <li><a href="https://huggingface.co/docs/transformers/main_classes/text_generation">Hugging Face Text Generation</a></li> <li><a href="https://github.com/huggingface/peft">Hugging Face Peft repository</a></li> </ul> <h2 id="peft-methods-in-general">PEFT Methods in General<a class="headerlink" href="#peft-methods-in-general" title="Permanent link">⚑</a></h2> <p>Full-fine tuning of large language LLMs is challenging. Fine-tuning requires storing training weights, optimizer states, gradients, forward activations and temporary memory. Things to store other than the weights can take up to 12-20 times more memory than the weights themselves. In full fine-tuning, every weight of the model is updated during training. PEFT methods only update a subset of the weights. They involve freezing most of the layers in the model and allowing only a small number of layers to be trained. Other methods don’t change the weights at all and instead, add new layers to the model and train only those layers. Due to this, the number of trainable weights is much smaller than the number of weights in the original LLM. This reduces the overall memory requirement for training, so much so that PEFT can often be performed on a single GPU. Since most of the LLM is left unchanged, PEFT is also less prone to Catastrophic Forgetting.</p> <h3 id="selective">Selective<a class="headerlink" href="#selective" title="Permanent link">⚑</a></h3> <p>We select a subset of initial LLM parameters to fine-tune. There are several approaches to select which subset of parameters we want to fine-tune. We can decide to train:</p> <ul> <li>Only certain components of the model.</li> <li>Specific layers of the model.</li> <li>Individual parameter types</li> </ul> <p>The performance of these approaches and the selective method overall is mixed. There are significant trade-offs in parameter efficiency and compute efficiency and hence, these methods are not very popular.</p> <h3 id="reparameterization">Reparameterization<a class="headerlink" href="#reparameterization" title="Permanent link">⚑</a></h3> <p>The model weights are reparameterized using a low-rank representation. Example techniques are Low Rank Adaptation (LoRA). More detail in its page:</p> <h3 id="additive">Additive<a class="headerlink" href="#additive" title="Permanent link">⚑</a></h3> <p>There are generally two methods:</p> <ul> <li>Adapters - New trainable layers are added to the model, typically inside the encoder or decoder blocks, after the FFNN or the attention layers.</li> <li>Prompt Tuning - The model architecture is kept fixed and instead, the input (prompt) is manipulated to obtain better performance. This can be done by adding trainable parameters to the prompt embeddings, or keeping the input fixed and retraining the embedding weights. Example techniques include Soft Prompts.</li> </ul> <h3 id="soft-prompts">Soft Prompts<a class="headerlink" href="#soft-prompts" title="Permanent link">⚑</a></h3> <p>Prompt tuning is not prompt engineering. Prompt engineering involves modifying the language of the prompt in order to “urge” the model to generate the completion that we want. This could be as simple as trying different words, phrases or including examples for In-Context Learning (ICL). The goal is to help the model understand the nature of the task and to generate better completions. This involves some limitations:</p> <ul> <li>We require a lot of manual effort to write and try different prompts.</li> <li>We are also limited by the length of the context window.</li> </ul> <p>Prompt tuning adds trainable “soft prompts” to inputs that are learnt during the supervised fine-tuning process. The set of trainable tokens is called a soft prompt. It is prepended to the embedding vectors that represent the input prompt. The soft prompt vectors have the same length as the embeddings. Generally, 20-100 “virtual tokens” can be sufficient for good performance.</p> <p>Prompt tuning does not involve updating the model. Instead, the model is completely frozen and only the soft prompt embedding vectors are updated to optimize the performance of the model on the original prompt. This is very efficient since a very small number of parameters are being trained (10, 000 to 100, 000).</p> <h3 id="hugging-face-peft-library">Hugging Face PEFT Library<a class="headerlink" href="#hugging-face-peft-library" title="Permanent link">⚑</a></h3> <h4 id="key-concepts">Key Concepts<a class="headerlink" href="#key-concepts" title="Permanent link">⚑</a></h4> <div class="language-text highlight"><pre><span></span><code>1. Hugging Face PEFT allows you to fine-tune a model without having to fine-tune
all of its parameters.

2. Training a model using Hugging Face PEFT requires two additional steps beyond
traditional fine-tuning:
</code></pre></div> <p>Creating a PEFT config Converting the model into a PEFT model using the PEFT config Inference using a PEFT model is almost identical to inference using a non-PEFT model. The only difference is that it must be loaded as a PEFT model.</p> <h4 id="training-peft">Training PEFT<a class="headerlink" href="#training-peft" title="Permanent link">⚑</a></h4> <p>The PEFT config specifies the adapter configuration for your parameter-efficient fine-tuning process. The base class for this is a <code>PeftConfig</code>, but this example will use a <code>LoraConfig</code>, the subclass used for low rank adaptation (LoRA).</p> <p>A LoRA config can be instantiated like this:</p> <div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a href="#__codelineno-8-1" id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">LoraConfig</span>
</span><span id="__span-8-2"><a href="#__codelineno-8-2" id="__codelineno-8-2" name="__codelineno-8-2"></a><span class="n">config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">()</span>
</span></code></pre></div> <p>Look at the LoRA adapter documentation for additional hyperparameters that can be specified by passing arguments to <code>LoraConfig()</code>. <a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora">The Hugging Face LoRA conceptual guide</a> also contains additional explanations.</p> <h2 id="instruction-fine-tuning">Instruction Fine-Tuning<a class="headerlink" href="#instruction-fine-tuning" title="Permanent link">⚑</a></h2> <p>Fine-tuning is the process of using labelled data to adapt a pre-trained model to a specific task or tasks. The data consists of prompt-completion pairs. Note that fine-tuning is applied on a pre-trained model and is supervised, as opposed to self-supervised.</p> <h3 id="limitations-of-icl">Limitations of ICL<a class="headerlink" href="#limitations-of-icl" title="Permanent link">⚑</a></h3> <p>We saw how some models are capable of identifying instructions contained in a prompt and correctly carrying out zero-shot inference. On the other hand, we also saw smaller models which fail to do so. In such cases, we use In-Context Learning (ICL) to make the model follow our instructions. There are some disadvantages to this:</p> <ul> <li>ICL may not always work for smaller models.</li> <li>Examples take up space in the context window, reducing the space available</li> </ul> <p>to add useful information in the prompt. To combat these disadvantages while having a model that can follow instructions, we can use instruction fine-tuning.</p> <p>Instruction fine-tuning is a fine-tuning technique used to improve a model’s performance on a variety of tasks. Here, the training samples are prompts containing instructions while the labels are the expected response of the model in order to follow that instruction:</p> <ul> <li>Example: If we want to fine-tune a model to improve its summarization ability, the dataset will contain prompts which look like as follows:</li> <li>Prompt: Summarize the following text (EXAMPLE TEXT)</li> <li>Completion: Summarize the following text (EXAMPLE TEXT) (EXAMPLE COMPLETION)</li> </ul> <p>Instruction fine-tuning where all of the model’s weights are updated is called full fine-tuning. This results in a new version of the model with updated weights. Note that full fine-tuning requires enough memory and compute budget to store all the gradients, optimizer states and other components updated during training (see Efficient Multi-GPU Compute Strategies).</p> <h3 id="common-steps-involved-in-instruction-fine-tuning">Common Steps Involved in Instruction Fine-Tuning<a class="headerlink" href="#common-steps-involved-in-instruction-fine-tuning" title="Permanent link">⚑</a></h3> <h4 id="prepare-the-dataset">Prepare the Dataset<a class="headerlink" href="#prepare-the-dataset" title="Permanent link">⚑</a></h4> <p>There are many publicly available datasets that have been used to train previous generations of LLMs. Most of these datasets are not formatted as instructions. Developers have built prompt template libraries that can be used to take existing datasets (for example, Amazon product reviews) and turn them into instruction prompt datasets for fine-tuning. Prompt template libraries include many templates for different tasks. For example:</p> <p><img alt="Prompt template" src="../../assets/images/promt_template.png"/></p> <p>Notice how each of the templates has an instruction in it: predict the associated rating, generate an x-star review and give a short sentence describing the following product review. The result is a prompt with an instruction and the example from the original dataset.</p> <h4 id="split-dataset">Split Dataset<a class="headerlink" href="#split-dataset" title="Permanent link">⚑</a></h4> <p>After the dataset is prepared, like any supervised problem, we split the dataset into training, validation and test sets.</p> <h4 id="training">Training<a class="headerlink" href="#training" title="Permanent link">⚑</a></h4> <p>The fine-tuning training loop is similar to any other supervised training loop:</p> <ul> <li>Pass the training data in batches to the model and obtain predictions.</li> <li>Calculate the loss. The output of an LLM is a probability distribution over the tokens available in the dataset. Thus, we can compare the probability distribution of the prediction with that of the label and use the standard cross-entropy loss to calculate the loss.</li> <li>Calculate some evaluation metric.</li> <li>Pass the validation data to the model and obtain predictions.</li> <li>Calculate the loss (optional) and the same evaluation metric.</li> <li>Backpropagate the loss to update the weights and repeat from the beginning as the next epoch. After training is done, we can evaluate the final performance of the model by passing it the test data and measuring the evaluation metric on model predictions. This process leads to a new version of the model, often called an Instruct Model. It tends to perform better at the tasks we have fine-tuned it for.</li> </ul> <h3 id="fine-tuning-on-a-single-task">Fine-Tuning On a Single Task<a class="headerlink" href="#fine-tuning-on-a-single-task" title="Permanent link">⚑</a></h3> <p>Fine-tuning on a single task can be done by simply using a single-task dataset. That is, all prompt-completion pairs in the dataset have the same basic instruction in them. Example: Summarize the following text: (EXAMPLE TEXT) (EXAMPLE COMPLETION) In most cases, only a small dataset (500-1000 examples) is required to achieve good performance on a single-task.</p> <h3 id="catastrophic-forgetting">Catastrophic Forgetting<a class="headerlink" href="#catastrophic-forgetting" title="Permanent link">⚑</a></h3> <p>Fine-tuning on a single task can lead to a problem called catastrophic forgetting. This happens since full fine-tuning changes the weights of the original LLM. This leads to great performance on the task we are fine-tuning for but can degrade performance on other tasks. For example, a model fine-tuned for sentiment analysis might become very good at the task, but might fail on something like named entity recognition despite being performant on it before fine-tuning.</p> <h4 id="avoiding-catastrophic-forgetting">Avoiding Catastrophic Forgetting<a class="headerlink" href="#avoiding-catastrophic-forgetting" title="Permanent link">⚑</a></h4> <p>First, we have to figure out whether our model is actually impacted by the problem. For example, if we require reliable performance only on the single task we are fine-tuning for, we do not need to worry about catastrophic forgetting. But, if we want the model to maintain its multi-task performance, we can perform fine-tuning on multiple tasks at the same time. This generally requires 50,000-100,000 examples across many tasks. Another alternative is Parameter Efficient Fine-Tuning (PEFT). PEFT preserves the weights of the original LLM and trains only a small number of task-specific adapter layers and parameters (see [Parameter Efficient Fine-Tuning.</p> <h3 id="fine-tuning-on-multiple-tasks">Fine-Tuning On Multiple Tasks<a class="headerlink" href="#fine-tuning-on-multiple-tasks" title="Permanent link">⚑</a></h3> <p>In case of multiple tasks, the dataset contains prompt-completion pairs related to multiple tasks. Example:</p> <ul> <li>Summarize the following text:</li> <li>Rate this review:</li> <li>Translate into Python code:</li> <li>Identify the places:</li> </ul> <p>The model is trained on this mixed dataset to fine-tune on multiple tasks simultaneously and remove the risk of catastrophic forgetting.</p> <h3 id="case-study-flan">Case Study - FLAN<a class="headerlink" href="#case-study-flan" title="Permanent link">⚑</a></h3> <p>FLAN (Fine-tuned Language Net) is a family of models fine-tuned on multiple tasks. FLAN models refer to a specific set of instructions used to perform instruction fine-tuning.</p> <p>FLAN-T5 is the FLAN instruct version of the T5 foundation model while FLAN-PALM is the FLAN instruct version of the PALM foundation model.</p> <p>FLAN-T5 is general purpose instruct model. It is fine-tuned on 473 datasets across 146 task categories. These datasets are chosen from other models and papers.</p> <p><img alt="Flan tasks" src="../../assets/images/flan_tasks.png"/></p> <p>For example, the SAMSum dataset is a text summarization dataset. SAMSum has 16,000 messenger-like conversations with their summaries. They were crafted by linguists for the express purpose of training LLMs.</p> <p>Note that while FLAN models are general-purpose, we might still need Domain Adaptation for it to make it work well for our application.</p> <h3 id="instruction-fine-tuning-resources">Instruction Fine tuning Resources<a class="headerlink" href="#instruction-fine-tuning-resources" title="Permanent link">⚑</a></h3> <ul> <li><a href="https://www.kaggle.com/code/diegofndz/create-a-bert-sentiment-classifier">Create a sentiment classifier with Bert</a></li> </ul> <hr/> <div class="md-source-file"> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class="timeago" datetime="2024-10-23T19:24:07+00:00" locale="en"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-10-23</span> <br/> Created: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class="timeago" datetime="2024-10-23T19:24:07+00:00" locale="en"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-10-23</span> </small> </div> <form class="md-feedback" hidden="" name="feedback"> <fieldset> <legend class="md-feedback__title"> Was this page helpful? </legend> <div class="md-feedback__inner"> <div class="md-feedback__list"> <button class="md-feedback__icon md-icon" data-md-value="1" title="This page was helpful" type="submit"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"></path></svg> </button> <button class="md-feedback__icon md-icon" data-md-value="0" title="This page could be improved" type="submit"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"></path></svg> </button> </div> <div class="md-feedback__note"> <div data-md-value="1" hidden=""> Thanks for your feedback! </div> <div data-md-value="0" hidden=""> Thanks for your feedback! Help us improve this page by using our <a href="..." rel="noopener" target="_blank">feedback form</a>. </div> </div> </div> </fieldset> </form> </article> </div> </div> <button class="md-top md-icon" data-md-component="top" hidden="" type="button"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> Back to top </button> </main> <footer class="md-footer"> <nav aria-label="Footer" class="md-footer__inner md-grid"> <a aria-label="Previous: Prompting" class="md-footer__link md-footer__link--prev" href="../prompting/" rel="prev"> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </div> <div class="md-footer__title"> <span class="md-footer__direction"> Previous </span> <div class="md-ellipsis"> Prompting </div> </div> </a> <a aria-label="Next: Reinforcement Learning From Human Feedback" class="md-footer__link md-footer__link--next" href="../Reinforcement%20Learning%20From%20Human%20Feedback/" rel="next"> <div class="md-footer__title"> <span class="md-footer__direction"> Next </span> <div class="md-ellipsis"> Reinforcement Learning From Human Feedback </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-copyright"> Made with <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank"> Material for MkDocs </a> </div> <div class="md-social"> <a class="md-social__link" href="https://github.com/diefergil" rel="noopener" target="_blank" title="github.com"> <svg viewbox="0 0 480 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg> </a> <a class="md-social__link" href="https://diefergil.github.io/personal-notes/newsletter/0_newsletter_index" rel="noopener" target="_blank" title="diefergil.github.io"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M0 64c0-17.7 14.3-32 32-32 229.8 0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7 0 64zm0 352a64 64 0 1 1 128 0 64 64 0 1 1-128 0zm32-256c159.1 0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7 0-32-14.3-32-32s14.3-32 32-32z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class="md-dialog" data-md-component="dialog"> <div class="md-dialog__inner md-typeset"></div> </div> <div class="md-consent" data-md-component="consent" hidden="" id="__consent"> <div class="md-consent__overlay"></div> <aside class="md-consent__inner"> <form class="md-consent__form md-grid md-typeset" name="consent"> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class="md-toggle" id="__settings" type="checkbox"/> <div class="md-consent__settings"> <ul class="task-list"> <li class="task-list-item"> <label class="task-list-control"> <input checked="" name="analytics" type="checkbox"/> <span class="task-list-indicator"></span> Google Analytics </label> </li> <li class="task-list-item"> <label class="task-list-control"> <input checked="" name="github" type="checkbox"/> <span class="task-list-indicator"></span> GitHub </label> </li> </ul> </div> <div class="md-consent__controls"> <button class="md-button md-button--primary">Accept</button> <label class="md-button" for="__settings">Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script> <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.footer", "navigation.instant", "navigation.top", "content.code.annotate", "search.suggest", "search.highlight", "content.code.copy", "content.code.select"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script> <script src="../../js/timeago.min.js"></script> <script src="../../js/timeago_mkdocs_material.js"></script> <script src="../../optionalConfig.js"></script> <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script> <script src="../../extra-loader.js"></script> <script src="../../javascripts/mathjax.js"></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </body> </html>
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a dynamic and powerful tool for building and training machine learning models. It simplifies the process with its fundamental building blocks like tensors and neural networks and offers effective ways to define objectives and improve models using loss functions and optimizers. By leveraging PyTorch, anyone can gain the skills to work with large amounts of data and develop cutting-edge AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a dynamic and powerful tool for building and training machine learning models. It simplifies the process with its fundamental building blocks like tensors and neural networks and offers effective ways to define objectives and improve models using loss functions and optimizers. By leveraging PyTorch, anyone can gain the skills to work with large amounts of data and develop cutting-edge AI applications.\n",
    "\n",
    "* Tensors: Generalized versions of vectors and matrices that can have any number of dimensions (i.e. multi-dimensional arrays). They hold data for processing with operations like addition or multiplication.\n",
    "\n",
    "* Matrix operations: Calculations involving matrices, which are two-dimensional arrays, like adding two matrices together or multiplying them.\n",
    "\n",
    "* Scalar values: Single numbers or quantities that only have magnitude, not direction (for example, the number 7 or 3.14).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images as PyTorch Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3-dimensional tensor\n",
    "images = torch.rand((4, 28, 28))\n",
    "\n",
    "# Get the second image\n",
    "second_image = images[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(second_image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 0]])\n",
      "tensor([[2, 1],\n",
      "        [1, 1]])\n",
      "tensor([[3, 2],\n",
      "        [2, 1]])\n",
      "tensor([[5, 3],\n",
      "        [3, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 1], [1, 0]])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(torch.matrix_power(a, 2))\n",
    "\n",
    "print(torch.matrix_power(a, 3))\n",
    "\n",
    "print(torch.matrix_power(a, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tensors tutorial](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n",
    "* [Tensors documentation](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch offers powerful features to create and interlink neural networks, which are key elements in understanding modern artificial intelligence. We explored creating a multi-layer perceptron using PyTorch's nn.Module class and then passed a tensor into it and received the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_layer): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (output_layer): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 64)\n",
    "        self.output_layer = nn.Linear(64, 2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "model = MLP(input_size=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0064, -0.1078], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.rand(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PyTorch nn tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "\n",
    "* [PyTorch nn documentation](https://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "* [torch.nn.Module documentation](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)\n",
    "\n",
    "* [torch.nn.Linear documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "\n",
    "* [torch.nn.ReLU documentation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch loss functions are essential tools that help in improving the accuracy of a model by measuring errors. These functions come in different forms to tackle various problems, like deciding between categories (classification) or predicting values (regression). Understanding and using these functions correctly is key to making smart, effective models that do a great job at the tasks they're designed for!\n",
    "\n",
    "* Loss functions: They measure how well a model is performing by calculating the difference between the model's predictions and the actual results.\n",
    "\n",
    "* Cross entropy loss: This is a measure used when a model needs to choose between categories (like whether an image shows a cat or a dog), and it shows how well the model's predictions align with the actual categories.\n",
    "\n",
    "* Mean squared error: This shows the average of the squares of the differences between predicted numbers (like a predicted price) and the actual numbers. It's often used for predicting continuous values rather than categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Our dataset contains a single image of a dog, where\n",
    "# cat = 0 and dog = 1 (corresponding to index 0 and 1) [Cat, Dog]\n",
    "target_tensor = torch.tensor([1])\n",
    "target_tensor\n",
    "# Prediction: Most likely a dog (index 1 is higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0486)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the values do not need to sum to 1\n",
    "predicted_tensor = torch.tensor([[2.0, 5.0]]) # two classes, the second larger == more likely\n",
    "loss_value = loss_function(predicted_tensor, target_tensor)\n",
    "loss_value\n",
    "# Prediction: Most likely a dog (index 1 is higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9130)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tensor = torch.tensor([[1.5, 1.1]])\n",
    "loss_value = loss_function(predicted_tensor, target_tensor)\n",
    "loss_value\n",
    "# Prediction: Slightly more likely a cat (index 0 is higher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000000.0\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Define the predicted and actual values as tensors\n",
    "predicted_tensor = torch.tensor([320000.0])\n",
    "actual_tensor = torch.tensor([300000.0])\n",
    "\n",
    "# Compute the MSE loss\n",
    "loss_value = loss_function(predicted_tensor, actual_tensor)\n",
    "print(loss_value.item())  # Loss value: 20000 * 20000 / 1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* [Index of PyTorch loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch optimizers are important tools that help improve how a neural network learns from data by adjusting the model's parameters. By using these optimizers, like stochastic gradient descent (SGD) with momentum or Adam, we can quickly get started learning!\n",
    "\n",
    "* Gradients: Directions and amounts by which a function increases most. The parameters can be changed in a direction opposite to the gradient of the loss function in order to reduce the loss.\n",
    "\n",
    "* Learning Rate: This hyperparameter specifies how big the steps are when adjusting the neural network's settings during training. Too big, and you might skip over the best setting; too small, and it'll take a very long time to get there.\n",
    "\n",
    "* Momentum: A technique that helps accelerate the optimizer in the right direction and dampens oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# momentum=0.9 smoothes out updates and can help training\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* [PyTorch optimization tutorial](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)\n",
    "\n",
    "* [Index of PyTorch optimizers](https://pytorch.org/docs/stable/optim.html#algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch makes accessing data for your model a breeze! These tools ensure that the flow of information to our AI is just right, making its learning experience effective and fun.\n",
    "\n",
    "* PyTorch Dataset class: This is like a recipe that tells your computer how to get the data it needs to learn from, including where to find it and how to parse it, if necessary.\n",
    "\n",
    "* PyTorch Data Loader: Think of this as a delivery truck that brings the data to your AI in small, manageable loads called batches; this makes it easier for the AI to process and learn from the data.\n",
    "\n",
    "* Batches: Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way.\n",
    "\n",
    "* Shuffle: It means mixing up the data so that it's not in the same order every time, which helps the AI learn better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((3, 4), 12)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Create a toy dataset\n",
    "class NumberProductDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = self.numbers[index]\n",
    "        number2 = self.numbers[index] + 1\n",
    "        return (number1, number2), number1 * number2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers)\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = NumberProductDataset(\n",
    "    data_range=(0, 11)\n",
    ")\n",
    "\n",
    "# Access a data sample\n",
    "data_sample = dataset[3]\n",
    "print(data_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 1, 2]), tensor([1, 2, 3])] tensor([0, 2, 6])\n",
      "[tensor([3, 4]), tensor([4, 5])] tensor([12, 20])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = NumberProductDataset(data_range=(0, 5))\n",
    "\n",
    "# Create a DataLoader instance\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=False)\n",
    "\n",
    "# Iterating over batches\n",
    "for num_pairs, products in dataloader:\n",
    "    print(num_pairs, products)\n",
    "    # 3 * 4 = 12\n",
    "    # 2 * 3 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PyTorch Dataset documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "\n",
    "* [PyTorch DataLoader documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "\n",
    "* [Index of PyTorch data utilities](https://pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyTorch training loop is an essential part of building a neural network model, which helps us teach the computer how to make predictions or decisions based on data. By using this loop, we gradually improve our model's accuracy through a process of learning from its mistakes and adjusting.\n",
    "\n",
    "* Training Loop: The cycle that a neural network goes through many times to learn from the data by making predictions, checking errors, and improving itself.\n",
    "\n",
    "* Batches: Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way.\n",
    "\n",
    "* Epochs: A complete pass through the entire training dataset. The more epochs, the more the computer goes over the material to learn.\n",
    "\n",
    "* Loss functions: They measure how well a model is performing by calculating the difference between the model's predictions and the actual results.\n",
    "\n",
    "* Optimizer: Part of the neural network's brain that makes decisions on how to change the network to get better at its job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Number Sum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([2., 1.]), tensor([3.]))\n",
      "(tensor([2., 2.]), tensor([4.]))\n",
      "(tensor([2., 3.]), tensor([5.]))\n",
      "(tensor([3., 1.]), tensor([4.]))\n",
      "(tensor([3., 2.]), tensor([5.]))\n",
      "(tensor([3., 3.]), tensor([6.]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class NumberSumDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This dataset has two features—a pair of numbers—and a \n",
    "    target value—the sum of those two numbers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2\n",
    "\n",
    "\n",
    "dataset = NumberSumDataset(data_range=(1, 4))\n",
    "\n",
    "for i in range(9):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Simple Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Components Needed for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(0, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Trainning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Losses = 0.01407\n",
      "Epoch 1: Sum of Batch Losses = 0.01828\n",
      "Epoch 2: Sum of Batch Losses = 0.01432\n",
      "Epoch 3: Sum of Batch Losses = 0.01933\n",
      "Epoch 4: Sum of Batch Losses = 0.01033\n",
      "Epoch 5: Sum of Batch Losses = 0.01055\n",
      "Epoch 6: Sum of Batch Losses = 0.01177\n",
      "Epoch 7: Sum of Batch Losses = 0.01076\n",
      "Epoch 8: Sum of Batch Losses = 0.00736\n",
      "Epoch 9: Sum of Batch Losses = 0.01118\n",
      "Epoch 10: Sum of Batch Losses = 0.00788\n",
      "Epoch 11: Sum of Batch Losses = 0.00741\n",
      "Epoch 12: Sum of Batch Losses = 0.00765\n",
      "Epoch 13: Sum of Batch Losses = 0.00764\n",
      "Epoch 14: Sum of Batch Losses = 0.00646\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):  # train for 15 epochs\n",
    "    loss = 0.0\n",
    "    for number_pairs, sums in dataloader:  # Iterate over the batches\n",
    "        predictions = model(number_pairs)  # Compute the model output\n",
    "        loss = loss_function(predictions, sums)  # Compute the loss\n",
    "        loss.backward()  # Perform backpropagation\n",
    "        optimizer.step()  # Update the parameters\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        loss += loss.item()  # Add the loss for all batches\n",
    "\n",
    "    print(\"Epoch {}: Sum of Batch Losses = {:.5f}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9170], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model on 3 + 7\n",
    "model(torch.tensor([3.0, 7.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "Home", "text": ""}, {"location": "#welcome-to-mkdocs", "title": "Welcome to MkDocs", "text": "<p>For full documentation visit mkdocs.org.</p>"}, {"location": "#commands", "title": "Commands", "text": "<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"}, {"location": "#project-layout", "title": "Project layout", "text": "<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"}, {"location": "about/", "title": "About", "text": ""}, {"location": "about/#pendet-illud-mutilatae-certa-urgetque-populi-radiis", "title": "Pendet illud mutilatae certa urgetque populi radiis", "text": ""}, {"location": "about/#et-nostra-quod-quamvis-tamen", "title": "Et nostra quod quamvis tamen", "text": "<p>Lorem markdownum erat perque, colebat dedit; collo habuit relictis falcato et fide mente iugulatus intrat. Tenet orbe ignoscite Saturnia valeant ulla neque orant positus mea aspicit aegide loquentem animae postquam cecidere aras. Prosilit quod ignavo in crinis metus unda, di Stygias florebat lacrimantem vellent nunc, et undis moenia mecum?</p>"}, {"location": "about/#ferat-teli-exitio-acrisius-et-modo-veteres", "title": "Ferat teli exitio Acrisius et modo veteres", "text": "<p>Idas feram an esse paruerit feres; cadet tonitruque nostra femur ipse. Ut errat tenet magni ultra n\u00e9 signa, sub, obstantis legit non, auctor.</p> <ul> <li>Haec quondam relaxant litora auxiliaria ferro Ampycides</li> <li>Corda sceleri</li> <li>Furiisque stimulis domos quod per palla</li> <li>Ire responderat legit i qua frugum fuit</li> <li>Ignarus nepotem do gravis</li> </ul>"}, {"location": "about/#et-averna-cernimus-adsuetos-aiax-interea-perque", "title": "Et Averna cernimus adsuetos Aiax interea perque", "text": "<p>Mihi aversa ignisque flumina: miscet: ab deo sive avidisque. Ad veni deponendique pars interdum Byblis noctem, sed nostro, nec satis ignotissima. Subitus longis, faciemque amorem. Nube ilia opus vulnere mentis mihi sorores referam sperato, hos ignis possedit et invenit, mens saecula aetas comitesque.</p>"}, {"location": "about/#montibus-aurora-barba-achaide", "title": "Montibus Aurora barba Achaide", "text": "<p>Tutaque verumque monimenta clamata et pretium gemellos latratu Minoa aequore; puerum. Tartareas priori inscripta spretae sua, iactat adspice peregrinosque metallis expellitur. Duobus sed vigoris illa mutatus, multicavo animosa!</p> <ul> <li>Abdita laticesque lepores ferro sibi suam per</li> <li>Litora sub Cecropide</li> <li>Me vincula quod dabat flumen mensuraque secura</li> <li>Pulsavere cantus redeuntem peritura</li> <li>Et luctatusque aequantia caedis praesagia montis certamina</li> <li>Suos est lucem fine velox ubi nam</li> </ul> <p>Fessos animis custodit cumque, Priamidas, lucem mihi Pyrrha; namque. Ille nihil: illo ultor nisi materque sit sensit, Cyllenaeo opus.</p>"}, {"location": "mlops/mlops_intro/", "title": "Introduction", "text": "", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#intro-to-mlops", "title": "Intro to MLops", "text": "<p>MLOps, or Machine Learning Operations, is a discipline that merges the # MLOps:  Unifying Machine Learning System Development and Operation</p> <p>MLOps, or Machine Learning Operations, is a discipline that merges the  development (Dev) and operation (Ops) of machine learning (ML) systems. As   data science and ML continue to become key capabilities for solving complex    real-world problems, the practice of MLOps is gaining traction. MLOps aims     to promote automation and monitoring throughout the construction of ML      systems, including integration, testing, release, deployment, and       infrastructure management.</p>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#mlops-is-more-than-just-ml-code", "title": "MLOps is More than Just ML Code", "text": "<p>The complexity of real-world ML systems goes beyond the ML code. The required  elements surrounding the ML code comprise a vast and intricate system that   includes configuration, automation, data collection, data verification,    testing and debugging, resource management, model analysis, process and     metadata management, serving infrastructure, and monitoring. In other words,     only a small fraction of an ML system is composed of the ML code      itself.</p>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#mlops-a-marriage-of-devops-and-machine-learning", "title": "MLOps: A Marriage of DevOps and Machine Learning", "text": "<p>Just as DevOps principles have proved beneficial in the development and  operation of large-scale software systems, these principles are applicable to   ML systems as well. However, ML systems have distinct characteristics:</p> <ol> <li>Team skills: An ML project typically involves data scientists or ML     researchers who might not be experienced software engineers capable of      building production-class services.</li> <li>Development: ML is experimental in nature. Challenges arise in tracking     what worked and what didn't, and maintaining reproducibility while      maximizing code reusability.</li> <li>Testing: Testing an ML system is more complex than testing other    software systems. It requires data validation, trained model quality     evaluation, and model validation.</li> <li>Deployment: Deployment in ML systems often entails deploying a     multi-step pipeline to automatically retrain and deploy models.</li> <li>Production: ML models can experience performance degradation due to     constantly evolving data profiles, necessitating the tracking of summary      statistics of data and monitoring of the online performance of models.</li> </ol>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#developing-ml-models-steps-to-success", "title": "Developing ML Models: Steps to Success", "text": "<p>Although the precise steps may vary depending on the specific ML project, a  general process can be outlined for developing ML models:</p> <ol> <li>Understanding the problem: This involves defining the business problem,     identifying the ML task, and preparing the initial data.</li> <li>Data preparation: This step includes gathering, cleaning, and     transforming data for the ML model.</li> <li>Model building: This includes selecting the model, training it, and then     evaluating its performance.</li> <li>Model deployment: This involves deploying the model into a production environment.</li> <li>Monitoring and maintenance: This step involves monitoring the     performance of the model over time, retraining it as necessary, and      performing model updates.</li> </ol>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#mlops-hierarchy-of-needs", "title": "MLops Hierarchy of needs", "text": "<p>To reach the Mlops level you have to achieve a few steps before you can reach  the next level. You cannot, for example, have DataOps without first   implementing devops.</p> <p>You need to achieve one step of the bottom</p>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#mlops-maturity-levels", "title": "MLOps Maturity Levels", "text": "<p>there are several different phases of going from a crude working where you can   barely get things into production and things are error-prone and manual all    the way to a very sophisticated system that has really end-to-end automation     and uses the next-generation features.</p> <ol> <li>Initial step: Experimentation. Establish the experimentation environment.</li> <li>Repeatable: standardize your code, your repos, make sure that there's maybe     a platform that you're using that can actually deploy the solution.</li> <li>Reliable: Test, monitoring, data drift, model versions.</li> <li>Scalable: You're able to templatize and productionize a lot of different ML     solutions, not just one, but actually have a scalable system that you can      repeat over and over again</li> </ol> Level Description Highlights Technology 0 No MLOps <ul><li>Difficult to manage full machine learning model lifecycle</li><li>The teams are disparate and releases are painful</li><li>Most systems exist as \"black boxes,\" little feedback during/post deployment</li><li>Manual builds and deployments</li><li>Manual testing of model and application</li><li>No centralized tracking of model performance</li><li>Training of model is manual</li></ul> 1 DevOps but no MLOps <ul><li>Releases are less painful than No MLOps, but rely on Data Team for every new model</li><li>Still limited feedback on how well a model performs in production</li><li>Difficult to trace/reproduce results</li></ul> <ul><li>Automated builds</li><li>Automated tests for application code</li></ul> 2 Automated Training <ul><li>Training environment is fully managed and traceable</li><li>Easy to reproduce model</li><li>Releases are manual, but low friction</li></ul> <ul><li>Automated model training</li><li>Centralized tracking of model training performance</li><li>Model management</li></ul> 3 Automated Model Deployment <ul><li>Releases are low friction and automatic</li><li>Full traceability from deployment back to original data</li><li>Entire environment managed: train &gt; test &gt; production</li></ul> <ul><li>Integrated A/B testing of model performance for deployment</li><li>Automated tests for all code</li><li>Centralized tracking of model training performance</li></ul> 4 Full MLOps Automated Operations <ul><li>Full system automated and easily monitored</li><li>Production systems are providing information on how to improve and, in some cases, automatically improve with new models</li><li>Approaching a zero-downtime system</li></ul> <ul><li>Automated model training and testing</li><li>Verbose, centralized metrics from deployed model</li></ul>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#level-0-no-mlops", "title": "Level 0: No MLOps", "text": "<ul> <li> <p>People: Data scientists, data engineers, and software engineers are    siloed and not in regular communications.</p> </li> <li> <p>Model Creation: Data is gathered manually, compute is likely not managed,    experiments aren't predictably tracked, and the end result may be a single     model file manually handed off.</p> </li> <li>Model Release: The release process is manual, and the scoring script may    be manually created well after experiments without version control.</li> <li>Application Integration: Heavily reliant on data scientist expertise to    implement and manual releases each time.</li> </ul>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#level-1-devops-no-mlops", "title": "Level 1: DevOps no MLOps", "text": "<ul> <li> <p>People: Same as Level 0.</p> </li> <li> <p>Model Creation: Data pipeline gathers data automatically, but compute may    not be managed, and experiments aren't predictably tracked.</p> </li> <li>Model Release: Still a manual process, but the scoring script is likely    version controlled and is handed off to software engineers.</li> <li>Application Integration: Basic integration tests exist, but still heavily    reliant on data scientist expertise. However, releases are automated and     application code has unit tests.</li> </ul>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#level-2-automated-training", "title": "Level 2: Automated Training", "text": "<ul> <li> <p>People: Data scientists work directly with data engineers to convert    experimentation code into repeatable scripts/jobs, while software engineers     remain siloed.</p> </li> <li> <p>Model Creation: Data pipeline gathers data automatically, compute is    managed, experiment results are tracked, and both training code and  resulting models are version controlled.</p> </li> <li>Model Release: Manual release, but the scoring script is version    controlled with tests and the release is managed by the software engineering     team.</li> <li>Application Integration: Same as Level 1.</li> </ul>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#level-3-automated-model-deployment", "title": "Level 3: Automated Model Deployment", "text": "<ul> <li> <p>People: Data scientists and data engineers work together and also with    software engineers to manage inputs/outputs and automate model integration     into application code.</p> </li> <li> <p>Model Creation: Same as Level 2.</p> </li> <li>Model Release: Release is automatic and managed by a continuous delivery    (CI/CD) pipeline.</li> <li>Application Integration: Unit and integration tests exist for each model    release, and the process is less reliant on data scientist expertise.     Application code has unit/integration tests..</li> </ul>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#level-4-full-mlops-automated-retraining", "title": "Level 4: Full MLOps Automated Retraining", "text": "<ul> <li> <p>People: All roles work together, with software engineers implementing    post-deployment metrics gathering.</p> </li> <li> <p>Model Creation: Similar to Level 3, but retraining is triggered    automatically based on production metrics.</p> </li> <li>Model Release: Same as Level 3.</li> </ul>", "tags": ["Mlops", "Introduction"]}, {"location": "mlops/mlops_intro/#references", "title": "References", "text": "<ul> <li>Google Mlops levels</li> <li>Microsoft Mlops levels</li> </ul>", "tags": ["Mlops", "Introduction"]}, {"location": "python/environments/", "title": "Virtual environments", "text": ""}, {"location": "python/environments/#virtualenv", "title": "virtualenv", "text": ""}, {"location": "python/environments/#create-an-environment", "title": "Create an environment", "text": "<pre><code>python -m venv .venv\nsource .venv/bin/activate\n</code></pre> <p>You can check the wheter the environment was activated or not doing:</p> <pre><code>which pip\n</code></pre> <p>And you should see something similar to:</p> <pre><code>usr/folder/.venv/bin/pip\n</code></pre>"}, {"location": "python/pytest/", "title": "Pytests", "text": "", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#pytest", "title": "Pytest", "text": "", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#test-layouts", "title": "Test layouts", "text": "<ul> <li>Directory layout starts with <code>tests</code></li> <li>From <code>tests</code> you can add anything like <code>unit</code>, <code>functional</code> or other meaningful   names like <code>database</code></li> <li>Files need to be pre-fixed with <code>test_</code></li> <li>Test functions need to be prefixed with <code>test_</code></li> <li>Test classes need to be prefixed with <code>Test</code></li> </ul>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#how-syntax-works", "title": "How syntax works", "text": "<p>Tests can be functions or classes</p>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#functions", "title": "Functions", "text": "<pre><code>def test_my_function():\n  assert 1 == 1\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#classes", "title": "Classes", "text": "<p>Classes do not need inheritance:</p> <p></p> <pre><code># This function is here for convenience only, in a real-world scenario this function\n# would be elsewhere in a package\n\ndef str_to_int(string):\n\"\"\"\n    Parses a string number into an integer, optionally converting to a float\n    and rounding down.\n    You can pass \"1.1\" which returns 1\n    [\"1\"] -&gt; raises RuntimeError\n    \"\"\"\n    error_msg = \"Unable to convert to integer: '%s'\" % str(string)\n    try:\n        integer = float(string.replace(',', '.'))\n    except AttributeError:\n        # this might be a integer already, so try to use it, otherwise raise\n        # the original exception\n        if isinstance(string, (int, float)):\n            integer = string\n        else:\n            raise RuntimeError(error_msg)\n    except (TypeError, ValueError):\n        raise RuntimeError(error_msg)\n\n    return int(integer)\n\n# When you create yout class test you have special methods\nclass TestStrToInt:\n\n    def setup_method(self):\n        print('\\nthis is setup')\n\n    def teardown_method(self):\n        print('\\nthis is teardown')\n\n    def setup_class(cls):\n        print('\\nthis is setup class')\n\n    def teardown_class(cls):\n        print('\\nthis is teardown class')\n\n    def test_rounds_down(self):\n        result = str_to_int('1.99')\n        assert result == 2\n\n    def test_round_down_lesser_half(self):\n        result = str_to_int('1.2')\n        assert result == 2\n</code></pre> <p>That setup_class is executed before a test in a class and happens just once, and setup_method is executed before every test in the class.</p> <p>You can use these special methods to run code before all tests in a class or before each one.</p> <p>You can see the ouput here:</p> Ouptut example <pre><code>======================================= test session starts =======================================\nplatform linux -- Python 3.8.10, pytest-7.2.0, pluggy-1.0.0\nrootdir: /home/coder/python-testing/notebooks/lesson2\ncollected 2 items\n\ntest-classes/test_classes.py FF                                                             [100%]\n\n============================================ FAILURES =============================================\n__________________________________ TestStrToInt.test_rounds_down __________________________________\n\nself = &lt;test_classes.TestStrToInt object at 0x7f9e8a8c8220&gt;\n\n    def test_rounds_down(self):\n        result = str_to_int('1.99')\n&gt;       assert result == 2\nE       assert 1 == 2\n\ntest-classes/test_classes.py:44: AssertionError\n-------------------------------------- Captured stdout setup --------------------------------------\n\nthis is setup class\n\nthis is setup\n------------------------------------ Captured stdout teardown -------------------------------------\n\nthis is teardown\n____________________________ TestStrToInt.test_round_down_lesser_half _____________________________\n\nself = &lt;test_classes.TestStrToInt object at 0x7f9e8a8c8340&gt;\n\n    def test_round_down_lesser_half(self):\n        result = str_to_int('1.2')\n&gt;       assert result == 2\nE       assert 1 == 2\n\ntest-classes/test_classes.py:48: AssertionError\n-------------------------------------- Captured stdout setup --------------------------------------\n\nthis is setup\n------------------------------------ Captured stdout teardown -------------------------------------\n\nthis is teardown\n\nthis is teardown class\n===================================== short test summary info =====================================\nFAILED test-classes/test_classes.py::TestStrToInt::test_rounds_down - assert 1 == 2\nFAILED test-classes/test_classes.py::TestStrToInt::test_round_down_lesser_half - assert 1 == 2\n======================================== 2 failed in 0.02s ========================================\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#run-tests", "title": "Run tests", "text": "<p>In the test directory</p> <pre><code>pytest -vvvv tests/\n</code></pre> Ouptut example <pre><code>============================= test session starts ==============================\nplatform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\ncachedir: .pytest_cache\nrootdir: /content, inifile:\n\ncollecting 0 items\ncollecting 2 items\ncollecting 2 items\ncollecting 2 items\ncollected 2 items\n\ntest_util.py::TestFloats::test_rounds_down FAILED                        [ 50%]\ntest_util.py::TestFloats::test_round_down_lesser_half FAILED             [100%]\n\n=================================== FAILURES ===================================\n_________________________ TestFloats.test_rounds_down __________________________\n\nself = &lt;test_util.TestFloats instance at 0x7fbf26d90870&gt;\n\n    def test_rounds_down(self):\n        result = str_to_int('1.99')\n&gt;       assert result == 2\nE       assert 1 == 2\n\ntest_util.py:42: AssertionError\nshow more (open the raw output data in a text editor) ...\n\n\nthis is teardown\n\nthis is teardown class\n=========================== 2 failed in 0.04 seconds ===========================\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#testing-failures", "title": "Testing failures", "text": "<p>Enter to the python debugger where your code is failing:</p> <pre><code>pytest --pdb test_failure_output.py\n</code></pre> <p>Once entered in the debugger you can type <code>h</code> to see the commands that you can use.</p>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#another-commands-for-pytest", "title": "Another commands for pytest", "text": "<ul> <li><code>--collect-only</code> -&gt; Only collect tests, don't execute them</li> <li><code>-x</code> -&gt; Stop at the first failure</li> </ul> <p>To see all type:</p> <pre><code>pytest --help\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#plugins", "title": "Plugins", "text": "", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#pytest-xdist", "title": "pytest-xdist", "text": "<p>Gives you the ability to run instance for running your test using the <code>-n</code> cli parameter.</p> <pre><code>pytest -n 4 test/\n</code></pre> <p>Going to set 4 differents runner instances and run them at the same time.</p>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#other-functionalities", "title": "Other functionalities", "text": "", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#parametrize-tests", "title": "Parametrize tests", "text": "<p>Parametrize tests it's like put a for loop over the tests that you want to expect  the same result using the same function. The problem with plain for loops it's  that the output it's a little bit confused. You don't know really where the error  is located and if the rest of the loop it's going to be cover. So a good  option it's parametrize tests.</p> str_to_bool function: <pre><code>  def str_to_bool(val):\n\"\"\"\n    Convert a string representation of truth to True or False\n    True values are 'y', 'yes', or ''; case-insensitive\n    False values are 'n', or 'no'; case-insensitive\n    Raises ValueError if 'val' is anything else.\n    \"\"\"\n    true_vals = ['yes', 'y', '']\n    false_vals = ['no', 'n']\n    try:\n        val = val.lower()\n    except AttributeError:\n        val = str(val).lower()\n    if val in true_vals:\n        return True\n    elif val in false_vals:\n        return False\n    else:\n        raise ValueError(\"Invalid input value: %s\" % val)\n</code></pre> <pre><code> import pytest\nfrom src impport str_to_bool # function to convert string to bool\n\n\n@pytest.mark.parametrize('value', ['y', 'yes', ''])\ndef test_is_true(value):\n    result = str_to_bool(value)\n    assert result is True\n</code></pre> Example output: <pre><code>======================================= test session starts =======================================\nplatform linux -- Python 3.8.10, pytest-7.2.0, pluggy-1.0.0\nrootdir: /home/coder/python-testing/notebooks/lesson2\ncollected 3 items\n\nparametrize/test_utils.py ...                                                               [100%]\n\n======================================== 3 passed in 0.01s ========================================\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#fixtures", "title": "Fixtures", "text": "<p>In pytest, fixtures are a way to provide data or test-doubles (mocks, stubs, etc) to your tests. They are created using the <code>@pytest.fixture</code> decorator and then injected into your tests as arguments. Fixtures are meant to simplify test setup and teardown code, and they help to make your tests more modular and scalable.</p> <p>Here's a basic example of how to use a fixture in pytest:</p> <pre><code>import pytest\n\n# Define a fixture\n@pytest.fixture\ndef my_fixture():\n    return \"Hello, World!\"\n\n# Use the fixture in a test\ndef test_hello(my_fixture):\n    assert my_fixture == \"Hello, World!\"\n</code></pre> <p>In this example, the <code>my_fixture</code> fixture is defined to return the string <code>\"Hello, World!\"</code>. Then, in the <code>test_hello</code> test, <code>my_fixture</code> is injected as an argument. When pytest runs this test, it first calls the my_fixture fixture function and then passes its return value to <code>test_hello</code>.</p> <p>Here's a more complex example where a fixture is used for setup and teardown:</p> <pre><code>import pytest\n\n# Define a fixture\n@pytest.fixture\ndef database():\n    db = setup_database()  # Setup code\n    yield db  # This is what will be injected into your tests\n    teardown_database(db)  # Teardown code\n\n# Use the fixture in a test\ndef test_db(database):\n    assert database.is_connected()\n</code></pre> <p>In this example, the <code>database</code> fixture is used to manage a database connection. The setup_database function is called to establish the connection, and then the connection object is yielded to the test. After the test runs, the <code>teardown_database</code> function is called to clean up the connection.</p>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#fixture-scopes", "title": "fixture scopes", "text": "<p>Fixture scope determines when a fixture is set up and torn down. The possible scopes are function, class, module, package or session:</p> <ul> <li><code>function</code>: The default scope, the fixture is set up and torn down for each test function.</li> <li><code>class</code>: The fixture is set up and torn down for each test class.</li> <li><code>module</code>: The fixture is set up and torn down once per test module.</li> <li><code>package</code>: The fixture is set up and torn down once per test package.</li> <li><code>session</code>: The fixture is set up once when the test session starts, and is torn down once at the end of the test session.</li> </ul> <pre><code>import pytest\n\n@pytest.fixture(scope=\"module\")\ndef module_fixture():\n    # Setup code here\n    yield \"Hello, Module!\"\n    # Teardown code here\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#fixture-dependencies", "title": "Fixture dependencies", "text": "<p>Fixtures can use other fixtures. This is often useful when you want to modularize your fixtures for reuse and better organization.</p> <pre><code>import pytest\n\n@pytest.fixture\ndef order():\n    return {\"name\": \"Burger\", \"price\": 7.99}\n\n@pytest.fixture\ndef cart(order):\n    return [order]\n\ndef test_cart(cart):\n    assert len(cart) == 1\n````\n\n#### conftest\n\nThe conftest.py file serves as a means of providing fixtures for an entire directory\nof tests. Any fixture defined in conftest.py will be automatically available to all\ntest files in the same directory and subdirectories.\n\n```python\n# conftest.py\nimport pytest\n\n@pytest.fixture\ndef my_fixture():\n    return \"Available Everywhere\"\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#temporal-directories", "title": "temporal directories", "text": "<p>The tmpdir fixture is a built-in pytest fixture that creates a temporary directory unique to the test invocation, which is automatically cleaned up after the test.</p> <pre><code>class TestMyClass:\n\n    def test_write_Yes(self, tmpdir):\n        path = str(tmpdir.join(\"test_value\"))\n        write_integer(\"Yes\", path)\n        with open(path, \"r\") as _f:\n            value = _f.read()\n\n        assert value == \"True\"\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/pytest/#monkeypatch", "title": "Monkeypatch", "text": "<p>The monkeypatch fixture helps to safely set/delete an attribute, dictionary item or environment variable or to modify sys.path for importing.</p> <pre><code>def test_monkeypatch(monkeypatch):\n    result = {\"HELLO\": \"world\"}\n    monkeypatch.setenv(\"HELLO\", \"monkeypatched\")\n    assert result[\"HELLO\"] == \"monkeypatched\"\n</code></pre>", "tags": ["Python", "Tests", "Development"]}, {"location": "python/apis/best_practices/", "title": "Best practices", "text": "", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#api-best-practices-with-fastapi-in-python", "title": "API Best Practices with FastAPI in Python", "text": "<p>Building APIs is a common task for backend developers, and they serve as the backbone of many modern web and mobile applications. However, designing and building an API can be a complex process, and it's important to follow best practices to ensure the resulting API is robust, reliable, and easy to use. This article presents API best practices with specific examples using FastAPI, a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#1-design-first-code-later", "title": "1. Design First, Code Later", "text": "<p>It's important to have a clear plan before starting to code your API. This means having a detailed specification of your API, including the routes, methods, parameters, and expected responses. You can create such a specification using the OpenAPI standard, which FastAPI supports out of the box.</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int):\n    return {\"item_id\": item_id}\n</code></pre> <p>In the above example, the OpenAPI schema is automatically generated and can be accessed at the <code>/docs</code> endpoint.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#2-consistent-and-restful-routing", "title": "2. Consistent and RESTful Routing", "text": "<p>Make sure your API routes are consistent and follow RESTful principles. This means using the correct HTTP methods (GET, POST, PUT, DELETE, etc.) and having meaningful, predictable URLs. FastAPI makes it easy to define these with Python decorators.</p> <pre><code>@app.get(\"/users/{user_id}\")\nasync def read_user(user_id: int):\n    # code to get user\n\n@app.post(\"/users/\")\nasync def create_user(user: User):\n    # code to create user\n</code></pre> HTTP Method Description Idempotent Safe GET Retrieves the current state of a resource. Read Only Yes Yes POST Creates a new resource. Write Only No No PUT Replaces the current state of a resource with a new state. Update existing Yes No PATCH Applies partial modifications to a resource. No No DELETE Deletes a resource. Yes No HEAD Similar to GET but only retrieves the headers of a response. DOes it exist? Yes Yes OPTIONS Returns the HTTP methods that the server supports for the specified URL. Yes Yes <ul> <li>Idempotent means that multiple identical requests should have the same effect    as a single request.</li> <li>Safe means that the method only retrieves data and does not modify it.</li> </ul>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#3-use-request-validation", "title": "3. Use Request Validation", "text": "<p>FastAPI supports request validation using Pydantic models, which allow you to define the expected shape of the data using Python type hints. This can significantly reduce the amount of boilerplate validation code you need to write.</p> <pre><code>from pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    description: str\n    price: float\n    tax: float = None\n\n@app.post(\"/items/\")\nasync def create_item(item: Item):\n    # code to create item\n</code></pre> <p>In this example, FastAPI will automatically validate that the incoming request data matches the <code>Item</code> model, and if it doesn't, it will return a helpful error message.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#4-error-handling", "title": "4. Error Handling", "text": "<p>You should anticipate and handle errors gracefully in your API. FastAPI provides the HTTPException class which you can raise to return a specific HTTP status code and message.</p> <pre><code>from fastapi import HTTPException\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int):\n    item = get_item(item_id)\n    if not item:\n        raise HTTPException(status_code=404, detail=\"Item not found\")\n    return item\n</code></pre> Error Type HTTP Status Code Description Bad Request 400 The server could not understand the request due to invalid syntax. Unauthorized 401 The client must authenticate itself to get the requested response. Forbidden 403 The client does not have access rights to the content; that is, it is unauthorized, so server is rejecting to give proper response. Not Found 404 The server can not find the requested resource. Method Not Allowed 405 The method specified in the request is not allowed for the resource identified by the request URI. Conflict 409 This response is sent when a request conflicts with the current state of the server. Internal Server Error 500 The server has encountered a situation it doesn't know how to handle. Service Unavailable 503 The server is not ready to handle the request. Common causes are a server that is down for maintenance or that is overloaded.", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#5-rate-limiting", "title": "5. Rate Limiting", "text": "<p>Protect your API from abuse and overuse by implementing rate limiting. While FastAPI doesn't have built-in support for rate limiting, you can use third-party libraries such as SlowApi.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#6-use-asynchronous-code", "title": "6. Use Asynchronous Code", "text": "<p>FastAPI supports asynchronous request handling using Python's async and await keywords. This can improve the performance of your API by allowing it to handle other requests while waiting for IO-bound tasks (like database queries) to complete.</p> <pre><code>@app.get(\"/items/\")\nasync def read_items():\n    items = await get_all_items()  # an async function that gets all items from the database\n    return items\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/best_practices/#7-logging-and-monitoring", "title": "7. Logging and Monitoring", "text": "<p>An essential aspect of maintaining and troubleshooting APIs is having robust logging and monitoring in place. Here are some best practices for logging and monitoring in FastAPI:</p> <ol> <li> <p>Use the standard library logging module: The logging module is a built-in Python     library that provides a flexible and powerful way to log messages from your     application. FastAPI has built-in support for the logging module, so you can easily     integrate it into your application\u200b1\u200b.</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\n@app.post(\"/items/\")\nasync def create_item(item: Item):\n    logger.info(f\"Creating item: {item.name}\")\n    # code to create item\n</code></pre> </li> <li> <p>Avoid using print() to log messages: print() does not provide the same level     of control and flexibility as other logging methods. Instead, use FastAPI\u2019s     built-in logger for more control over how messages are logged, including setting     log levels, adding contextual information, and formatting logs for easier readability\u200b1\u200b.</p> </li> <li> <p>Log as much information as possible: By logging detailed information, such as     the request URL, query parameters, headers, body, response status code, and more,     developers can easily pinpoint where an issue occurred and what caused it.     Use structured loggers to log data in a consistent format that can be easily     parsed by other tools\u200b1\u200b.</p> </li> <li> <p>Log exceptions: Logging exceptions allows developers to quickly identify and     debug errors in their applications. By logging exceptions, developers can     easily pinpoint where an issue occurred and what caused it. To log exceptions     with FastAPI, use a library like Python\u2019s built-in logging module\u200b1\u200b.</p> </li> <li> <p>Add context to your logs: Adding context to your logs helps you quickly identify     the source of an issue. By adding contextual information such as request and     response data, user IDs, or other relevant details, you can easily pinpoint     where the issue originated from\u200b1\u200b.</p> </li> <li> <p>Use a structured logger: Structured logging is a way of formatting log messages     so that they are easier to read and parse. FastAPI provides built-in support     for structured logging via its Logging middleware\u200b1\u200b.</p> </li> <li> <p>Configure your logger for production: Configuring your logger for production     ensures that the right information is being logged at the right time. This     includes setting up log levels so that only important messages are recorded,     and configuring the format of the logs so they are easy to read and interpret.     Additionally, ensure that sensitive data is not included in the logs, and     that access to the logs is restricted to authorized personnel\u200b1\u200b.</p> </li> <li> <p>Use an external service to store and analyze logs: Using an external service     to store logs is beneficial because it allows for more efficient log     management. Additionally, these services typically offer a range of features     such as real-time monitoring, alerting, and reporting capabilities\u200b1\u200b.</p> </li> </ol>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/", "title": "FastAPI", "text": "", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#fastapi", "title": "FastApi", "text": "<p>FastAPI is a modern, fast (high-performance), web framework for building APIs with  Python 3.6+ based on standard Python type hints.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#installation", "title": "Installation", "text": "<p>To install FastAPI, you'll need a Python version of 3.6 or greater. You can install  it using pip:</p> <pre><code>pip install fastapi\npip install uvicorn\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#baseic-example", "title": "Baseic example", "text": "<p>Here's a basic example of a FastAPI application:</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n</code></pre> <p>You can run the application using Uvicorn:</p> <pre><code>uvicorn main:app --reload\n</code></pre> <p>This command refers to:</p> <ul> <li><code>uvicorn</code>: Python framework that allows us to run a python application.</li> <li><code>main</code>: the file main.py (the Python \"module\").</li> <li><code>app</code>: the object created inside of main.py with the line app = FastAPI().</li> <li><code>--reload</code>: make the server restart after code changes. Only do this for development.</li> </ul>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#path-parameters", "title": "Path parameters", "text": "<p>You can define path parameters by putting them in curly braces {} in the path of the  route decorator:</p> <p>You can define path parameters by putting them in curly braces {} in the path of the  route decorator:</p> <pre><code>@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int):\n    return {\"item_id\": item_id}\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#query-parameters", "title": "Query Parameters", "text": "<p>If you want the client to send additional data, but not in the path, you can use  query parameters:</p> <pre><code>from typing import Optional\n\n@app.get(\"/items/\")\ndef read_items(q: Optional[str] = None):\n    if q:\n        return {\"item\": q}\n    return {\"item\": \"not found\"}\n</code></pre> <p>In this case, <code>q</code> is an optional string query parameter.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#request-body", "title": "Request Body", "text": "", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#type-hints", "title": "Type hints", "text": "<p>FastAPI automatically recognizes Python type hints in the function parameters:</p> <pre><code>from pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    description: Optional[str] = None\n    price: float\n    tax: Optional[float] = None\n\n@app.post(\"/items/\")\ndef create_item(item: Item):\n    return item\n</code></pre> <p>In this example, the item body request parameter is declared to be of type Item.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#example-script", "title": "Example script", "text": "<pre><code>from datetime import datetime\nfrom os.path import dirname, abspath, join\nfrom fastapi import FastAPI\nfrom fastapi.responses import FileResponse # for serving files\nfrom fastapi.staticfiles import StaticFiles # for serving static files\nfrom pydantic import BaseModel\n\ncurrent_dir = dirname(abspath(__file__)) # get the path of the current script\nstatic_path = join(current_dir, \"static\") #\u00a0\n\napp = FastAPI()\napp.mount(\"/ui\", StaticFiles(directory=static_path), name=\"ui\")\n\nclass Body(BaseModel):\n    strftime: str\n\n\n@app.get('/')\ndef root():\n    html_path = join(static_path, \"index.html\")\n    return FileResponse(html_path)\n\n\n@app.post('/generate')\ndef generate(body: Body):\n\"\"\"\n    Generate the current time given a strftime template. For example:\n    '%Y-%m-%dT%H:%M:%S.%f'\n    \"\"\"\n    tmpl = body.strftime or '%Y-%m-%dT%H:%M:%S.%f'\n    return {'date': datetime.now().strftime(tmpl)}\n\n@app.post('/azure_cognitive')\ndef azure_cognitive(body: Body):\n\"\"\"\n    Put here your code to create an Azure Cognitive service endpoint!\n    \"\"\"\n    return {'result': None} # Change None\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/fastapi/#why-use-uvicorn", "title": "Why use uvicorn", "text": "<p>Uvicorn is an ASGI (Asynchronous Server Gateway Interface) server that is used to  run your FastAPI application. The ASGI specification fills in the gap left by the     traditional WSGI servers used for synchronous Python web applications, and allows    for greater concurrency and the use of long-lived connections, which are required     for modern web applications that need to handle things like WebSockets and HTTP/2.</p> <p>Here are some of the features that Uvicorn provides when used with FastAPI:</p> <ul> <li> <p>Performance: Uvicorn is one of the fastest ASGI servers due to its minimal and   highly optimized code base. It's built on uvloop and httptools, which are   themselves very fast asynchronous I/O and HTTP parsing libraries, respectively.</p> </li> <li> <p>Concurrency: By supporting the ASGI specification, Uvicorn allows FastAPI applications to handle many connections concurrently. This is great for applications that need to handle long-lived connections, such as WebSocket connections, in addition to regular HTTP requests.</p> </li> <li> <p>Hot Reload: Uvicorn supports hot reloading, which means it can automatically restart the server whenever it detects changes to your source code. This is extremely useful during development.</p> </li> <li> <p>WebSockets and HTTP/2 Support: ASGI servers like Uvicorn can handle long-lived  connections, such as WebSocket connections, which can be used for real-time   communication between the server and the client. They also support HTTP/2,   which can provide performance benefits over HTTP/1.</p> </li> <li> <p>Integration with FastAPI: FastAPI is built to work seamlessly with Uvicorn and other ASGI servers. This means you can take full advantage of all the features provided by FastAPI and ASGI, while still getting the performance benefits of Uvicorn.</p> </li> </ul>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/", "title": "Flask", "text": "", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#flask", "title": "Flask", "text": "<p>Flask is a web framework for Python, it's lightweight and easy to understand.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#setup", "title": "Setup", "text": "<p>First, we need to install Flask. We can do this with pip:</p> <pre><code>pip install flask\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#you-first-flask-application", "title": "You first Flask application", "text": "<p>Here's a basic Flask application:</p> <pre><code>from flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello_world():\n    return 'Hello, World!'\n\nif __name__ == \"__main__\":\n    app.run()\n</code></pre> <p>Here's what this code does:</p> <ul> <li><code>from flask import Flask</code> imports the Flask module.</li> <li><code>app = Flask(__name__)</code> creates an instance of the Flask class for our application.</li> <li><code>@app.route('/')</code> is a decorator that tells Flask what URL should trigger the   function that follows.</li> <li><code>def hello_world():</code> defines a function that returns the string 'Hello, World!'</li> <li><code>if __name__ == \"__main__\": app.run()</code> runs the application on the local   development server.</li> </ul> <p>To run the application, save the above code in a file called app.py, then run  python app.py from your terminal. You should see output indicating that the  server is running, and you can visit http://localhost:5000 in your web browser   to view your application.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#run-flask-api", "title": "Run flask api", "text": "<p>You can now run your Flask app by using the following command in your terminal:</p> <pre><code>python app.py\n</code></pre> <p>Then, open your web browser and navigate to <code>http://127.0.0.1:5000/</code>. You should see the text \"Hello, World!\" displayed.</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#add-more-routes", "title": "Add more routes", "text": "<p>Flask allows you to add more decorators to create more routes. Here's how you can  create a new route:</p> <pre><code>@app.route('/about')\ndef about():\n    return 'About Page'\n</code></pre> <p>Now, if you navigate to <code>http://127.0.0.1:5000/about</code>, you will see the text \"About Page\".</p>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#script-example", "title": "Script example", "text": "<pre><code>from flask import Flask, abort\n\napp = Flask(__name__)\n\n@app.route('/') # / equals to the root of the website\ndef hello_world():\n    return 'Hello, World!'\n\n@app.route('/error')\ndef error():\n    abort(500, 'oooh some error!')\n\nif __name__ == \"__main__\":\n    app.run(debug=True, port=8000, host='0.0.0.0')\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#llm-model-with-flask-roberta", "title": "LLM model with flask (RoBERTa)", "text": "<pre><code>from flask import Flask, request, jsonify\nimport torch\nimport numpy as np\nfrom transformers import RobertaTokenizer\nimport onnxruntime\n\n\napp = Flask(__name__)\ntokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\nsession = onnxruntime.InferenceSession(\"roberta-sequence-classification-9.onnx\")\n\n\ndef to_numpy(tensor):\n    return (\n        tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n    )\n\n\n@app.route(\"/\")\ndef home():\n    return \"&lt;h2&gt;RoBERTa sentiment analysis&lt;/h2&gt;\"\n\n\n@app.route(\"/predict\", methods=[\"POST\"])\ndef predict():\n    input_ids = torch.tensor(\n        tokenizer.encode(request.json[0], add_special_tokens=True)\n    ).unsqueeze(\n        0\n    )\n\n    inputs = {session.get_inputs()[0].name: to_numpy(input_ids)}\n    out = session.run(None, inputs)\n\n    result = np.argmax(out)\n\n    return jsonify({\"positive\": bool(result)})\n\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n</code></pre> <ul> <li><code>roberta-sequence-classification-9.onnx</code> The model was donwloaded.</li> </ul>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/apis/flask/#send-a-post", "title": "Send a post", "text": "<pre><code>curl -X POST --header \"Content-Type: application/json\"\\\n--data '[\"using curl is not to my liking\"]'\\\nhttp:/127.0.0.1:5000/predict\n</code></pre>", "tags": ["Development", "Application Programming Interface"]}, {"location": "python/cli/argparse/", "title": "Argparse", "text": "", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#argparse", "title": "Argparse", "text": "", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#introduction-to-argparse-in-python", "title": "Introduction to <code>argparse</code> in Python", "text": "<p><code>argparse</code> is a powerful module in Python that provides a convenient way to parse command-line arguments and options. It simplifies the process of building command-line interfaces (CLIs) for your Python scripts or applications. In this tutorial, we will explore the basics of <code>argparse</code> and learn how to use it effectively.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#installation-of-argparse", "title": "Installation of argparse", "text": "<p><code>argparse</code> is included in the Python standard library, so there is no need for  additional installation.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#getting-started", "title": "Getting Started", "text": "<p>To start using <code>argparse</code>, you need to import the module:</p> <pre><code>import argparse\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#creating-a-parser", "title": "Creating a Parser", "text": "<p>The first step in using <code>argparse</code> is to create an ArgumentParser object, which will  handle the parsing of command-line arguments. You can create a parser by invoking  the <code>argparse.ArgumentParser()</code> constructor:</p> <pre><code>parser = argparse.ArgumentParser()\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#adding-arguments", "title": "Adding Arguments", "text": "<p>Once you have a parser, you can add arguments to it. An argument is defined by invoking the <code>add_argument()</code> method on the parser object. Here\\'s an example that adds a positional argument:</p> <pre><code>parser.add_argument('filename', help='name of the file to process')\n</code></pre> <p>In the example above, we added a positional argument called <code>filename</code> that represents the name of the file to be processed. The <code>help</code> parameter provides a description of the argument, which is displayed when the user requests help information.</p> <p>You can also add optional arguments using the <code>add_argument()</code> method. Here's an example that adds an optional argument called <code>--verbose</code>:</p> <pre><code>parser.add_argument(\n    '--verbose', action='store_true', help='increase output verbosity'\n    )\n</code></pre> <p>In the example above, we added a positional argument called filename that represents the name of the file to be processed. The help parameter provides a description of the argument, which is displayed when the user requests help information.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#parsing-arguments", "title": "Parsing Arguments", "text": "<p>After you have added the desired arguments, you need to parse the command-line arguments provided by the user. This is done by invoking the <code>parse_args()</code> method on the parser object:</p> <pre><code>args = parser.parse_args()\n</code></pre> <p>The <code>parse_args()</code> method returns an object containing the values of the parsed  arguments. You can access the values by using dot notation on the <code>args</code> object.   For example, to access the value of the <code>filename</code> argument:</p> <pre><code>print(args.filename)\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#putting-it-all-together", "title": "Putting It All Together", "text": "<p>Here's an example that combines the concepts discussed above:</p> <pre><code>import argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('filename', help='name of the file to process')\nparser.add_argument('--verbose', action='store_true', help='increase output verbosity')\n\nargs = parser.parse_args()\n\nprint('Processing file:', args.filename)\nif args.verbose:\n    print(\"Verbose mode enabled.\")\n</code></pre> <p>ssuming this script is saved as <code>script.py</code>, you can run it from the command line as follows:</p> <pre><code>python script.py myfile.txt\n</code></pre> <p>If you include the <code>--verbose</code> flag:</p> <pre><code>python script.py myfile.txt --verbose\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/argparse/#example-script-of-argparse", "title": "Example script of argparse", "text": "<pre><code>import argparse\n\ndef greet_user(name, age=None, greeting='Hello', uppercase=False):\n    # Modify greeting based on options\n    if uppercase:\n        greeting = greeting.upper()\n\n    # Greet the user\n    output = f'{greeting}, {name}!'\n    if age:\n        output += f' You are {age} years old.'\n\n    return output\n\nif __name__ == '__main__':\n    # Create a parser\n    parser = argparse.ArgumentParser(description='Script to greet a user')\n\n    # Add arguments\n    parser.add_argument('name', help='name of the user')  # positional argument\n    parser.add_argument('--age', type=int, help='age of the user')  # optional argument with type validation\n    parser.add_argument('--greeting', choices=['Hello', 'Hi', 'Hola'], default='Hello',\n                        help='choose a greeting from the given options')  # optional argument with choices and default value\n    parser.add_argument('--uppercase', action='store_true', help='convert greeting to uppercase')  # optional argument with flag\n\n    # Parse the arguments\n    args = parser.parse_args()\n\n    # Call the greet_user function with the provided arguments\n    output = greet_user(args.name, args.age, args.greeting, args.uppercase)\n\n    # Print the greeting\n    print(output)\n</code></pre> <p>Clarifications:     * When an argument has a action, by default is <code>False</code> until you put it in the     call to enable it, in this case it is <code>--sort</code>argument.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/", "title": "Click", "text": "", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#click-command-line-python-framework-tutorial", "title": "Click Command Line Python Framework Tutorial", "text": "<p>Click is a Python package that allows for the creation of beautiful command line interfaces (CLI) in a composable way. It's perfect for building command line applications and supports lazy argument parsing.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#installation", "title": "Installation", "text": "<p>First, we need to install Click. You can do this using pip:</p> <pre><code>pip install click\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#a-basic-click-command", "title": "A Basic Click Command", "text": "<p>Here is an example of a simple Click command:</p> <pre><code>import click\n\n@click.command()\ndef hello():\n    click.echo('Hello Click!')\n\nif __name__ == '__main__':\n    hello()\n</code></pre> <p>In this script,<code>@click.command()</code> is a decorator which tells Click that this +\u00a1 function is a command line command. <code>click.echo</code> is a function that prints text to the console.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#command-with-arguments", "title": "Command with Arguments", "text": "<p>We can add arguments to our Click commands as follows:</p> <pre><code>import click\n\n@click.command()\n@click.argument('name')\ndef hello(name):\n    click.echo(f'Hello {name}!')\n\nif __name__ == '__main__':\n    hello()\n</code></pre> <p>In this example, <code>@click.argument('name')</code> is another decorator which adds an argument to our command. Now, when you run the command, you need to provide an additional piece of information.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#command-with-options", "title": "Command with Options", "text": "<p>Options are like arguments, but they are optional and have default values:</p> <pre><code>import click\n\n@click.command()\n@click.option('--greeting', default='Hello', help='Change the greeting.')\n@click.argument('name')\ndef hello(greeting, name):\n    click.echo(f'{greeting} {name}!')\n\nif __name__ == '__main__':\n    hello()\n</code></pre> <p>In this example, <code>@click.option('--greeting', default='Hello', help='Change the greeting.')</code> is an option. You can provide it when you run the command, or you can leave it out to use the default value.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#grouping-commands", "title": "Grouping commands", "text": "<p>You can group multiple commands together:</p> <pre><code>import click\n\n@click.group()\ndef cli():\n    pass\n\n@cli.command()\ndef initdb():\n    click.echo('Initialized the database')\n\n@cli.command()\ndef dropdb():\n    click.echo('Dropped the database')\n\nif __name__ == '__main__':\n    cli()\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#example-click-script", "title": "Example click script", "text": "<pre><code>import click\n\n@click.group()\ndef cli():\n    'Example CLI group. This is a Click command-line interface.'\n    pass\n\n@cli.command()\n@click.argument('name', nargs=1)\ndef greet(name):\n    'This command greets NAME.'\n    click.echo(f'Hello, {name}!')\n\n@cli.command()\n@click.argument('name', nargs=1)\n@click.option('--count', default=1, help='Number of greetings.')\n@click.option('--greeting', '-g', default='Hello', help='Customize the greeting.')\ndef repeat(name, count, greeting):\n    'This command repeats a greeting to NAME, COUNT times.'\n    for _ in range(count):\n        click.echo(f'{greeting}, {name}!')\n\n@cli.group()\ndef maths():\n    'Maths commands group.'\n    pass\n\n@maths.command()\n@click.argument('numbers', nargs=-1, type=int)\ndef sum(numbers):\n    'This command sums up NUMBERS.'\n    click.echo(f'Sum: {sum(numbers)}')\n\n@maths.command()\n@click.argument('numbers', nargs=-1, type=int)\ndef multiply(numbers):\n    'This command multiplies NUMBERS.'\n    result = 1\n    for num in numbers:\n        result *= num\n    click.echo(f'Product: {result}')\n\n@cli.command()\n@click.argument('filepath', type=click.Path(exists=True))\ndef showfile(filepath):\n    'This command shows the content of a FILEPATH.'\n    with open(filepath, 'r') as file:\n        content = file.read()\n    click.echo(content)\n\nif __name__ == '__main__':\n    cli()\n</code></pre> <p>This script provides a command-line interface with a <code>greet</code> command that accepts one argument (a name to greet), a <code>repeat</code> command that accepts a name and optional count and greeting options (to repeat the greeting a certain number of times), and a <code>maths</code> group with <code>sum</code> and <code>multiply</code> commands that perform mathematical operations on a list of numbers.</p> <p>You can run these commands like so:</p> <pre><code>python myscript.py greet Bob\npython myscript.py repeat Alice --count 3 --greeting Hi\npython myscript.py maths sum 1 2 3 4 5\npython myscript.py maths multiply 1 2 3 4 5\npython myscript.py showfile /path/to/file\n</code></pre>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#argument-vs-option", "title": "Argument vs Option", "text": "<p>In the context of command-line interfaces, the terms \"argument\" and \"option\" have specific meanings:</p> <ul> <li> <p>Argument: An argument is a value that is passed directly to a command. Arguments   are positional, meaning that their order matters. They are typically mandatory,    although some commands may allow optional arguments. For example, in the     command <code>cp source.txt dest.txt</code>, <code>source.txt</code> and <code>dest.txt</code> are arguments.</p> </li> <li> <p>Option: An option modifies the behavior of a command. It is usually prefixed    by a - (single dash for single-character options) or -- (double dash for    multi-character options). Options may or may not require a value to be provided.     For example, in the command <code>ls -l</code>, <code>-l</code> is an option that modifies the behavior     of the ls command.</p> </li> </ul> <p>In the context of the Click library in Python:</p> <ul> <li> <p>Argument: Click treats arguments similarly to how they are treated in     command-line interfaces. They are positional and are defined using the     <code>@click.argument()</code> decorator.</p> </li> <li> <p>Option: Click treats options as modifiers of commands. They are defined using     the <code>@click.option()</code> decorator, and can have default values. Options in Click     are always optional, and if not provided in the command line, the default value     is used.</p> </li> </ul> <p>Here's an example of a command in Click that uses both arguments and options:</p> <pre><code>@click.command()\n@click.argument('filename')\n@click.option('--verbose', is_flag=True, help='Enable verbose mode.')\ndef process(filename, verbose):\n\"\"\"Process a file. If --verbose is provided, print detailed information.\"\"\"\n    if verbose:\n        click.echo(f'Processing file in verbose mode: {filename}')\n    else:\n        click.echo(f'Processing file: {filename}')\n</code></pre> <p>In this example, filename is an argument, and <code>--verbose</code> is an option. The <code>is_flag=True</code> argument to <code>@click.option()</code> means that <code>--verbose</code> is a flag that does not take a value; its presence in the command line sets verbose to True.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/cli/click/#create-an-unique-unique-entrypoint-in-click", "title": "Create an unique unique entrypoint in click", "text": "<p>If you have multiple command groups defined across different files, you can import them into a main file and create an entry point for your application. This way, you can keep your command groups logically separated, which can be beneficial as your application grows.</p> <p>Here's an example:</p> <p>Let's say you have two Python files, <code>file1.py</code> and <code>file2.py</code>, with different c ommand groups.</p> <p><code>file1.py</code>:</p> <pre><code>import click\n\n@click.group()\ndef group1():\n\"\"\"This is group1 commands.\"\"\"\n    pass\n\n@group1.command()\ndef command1():\n    click.echo(\"Executing command1 from group1.\")\n\n@group1.command()\ndef command2():\n    click.echo(\"Executing command2 from group1.\")\n</code></pre> <p><code>file2.py</code>:</p> <pre><code>import click\n\n@click.group()\ndef group2():\n\"\"\"This is group2 commands.\"\"\"\n    pass\n\n@group2.command()\ndef command1():\n    click.echo(\"Executing command1 from group2.\")\n\n@group2.command()\ndef command2():\n    click.echo(\"Executing command2 from group2.\")\n</code></pre> <p>You can then create an entry point in a main file (for example, main.py) that imports these groups and adds them to the main command group:</p> <p><code>main.py</code>:</p> <pre><code>import click\nfrom file1 import group1\nfrom file2 import group2\n\n@click.group()\ndef cli():\n\"\"\"This is the main entry point.\"\"\"\n    pass\n\ncli.add_command(group1)\ncli.add_command(group2)\n\nif __name__ == '__main__':\n    cli()\n</code></pre> <p>Now, when you run <code>python main.py</code>, you'll have access to both command groups, <code>group1</code> and <code>group2</code>, and all their respective commands. The commands can be accessed like this:</p> <pre><code>python main.py group1 command1\n</code></pre> <p>Please note that the import statements in <code>main.py</code> assume that <code>file1.py</code> and <code>file2.py</code> are in the same directory as <code>main.py</code>. If they're not, you'll need to adjust the import statements to match your directory structure.</p>", "tags": ["Development", "Command Line interface"]}, {"location": "python/nlp/huggingface/", "title": "HuggingFace", "text": ""}, {"location": "python/nlp/huggingface/#hugginface", "title": "Hugginface", "text": ""}, {"location": "python/nlp/huggingface/#transformers", "title": "\ud83e\udd17 Transformers", "text": "<p>Load State-of-the-art Machine Learning models for PyTorch, TensorFlow, and JAX dynamically.</p> <p>\ud83e\udd17 Transformers provides APIs and tools to easily download and train state-of-the-art  pretrained models. Using pretrained models can reduce your compute costs, carbon   footprint, and save you the time and resources required to train a model from   scratch. These models support common tasks in different modalities, such as:</p> <p>\ud83d\udcdd Natural Language Processing: text classification, named entity recognition,  question answering, language modeling, summarization, translation, multiple  choice, and text generation. \ud83d\uddbc\ufe0f Computer Vision: image classification, object detection, and segmentation. \ud83d\udde3\ufe0f Audio: automatic speech recognition and audio classification. \ud83d\udc19 Multimodal: table question answering, optical character recognition, information  extraction from scanned documents, video classification, and visual question answering.</p> <p>\ud83e\udd17 Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage  of a model\u2019s life; train a model in three lines of code in one framework, and  load it for inference in another. Models can also be exported to a format like  ONNX and TorchScript for deployment in production environments.</p>"}, {"location": "python/nlp/huggingface/#install-hugginface-tansformers", "title": "Install Hugginface tansformers", "text": "<p>Installation</p> Normal instalationpytorchtensorflow <pre><code>pip install transformers\n</code></pre> <pre><code>pip install 'transformers[torch]'\n</code></pre> <pre><code>pip install 'transformers[tf-cpu]'\n</code></pre>"}, {"location": "python/nlp/huggingface/#pipeline", "title": "Pipeline", "text": ""}, {"location": "python/nlp/huggingface/#datasets", "title": "Datasets", "text": "<p>\ud83e\udd17 Datasets is a library for easily accessing and sharing datasets for Audio, Computer Vision, and Natural Language Processing (NLP) tasks.</p> <p>Load a dataset in a single line of code, and use our powerful data processing methods to quickly get your dataset ready for training in a deep learning model. Backed by the Apache Arrow format, process large datasets with zero-copy reads without any memory constraints for optimal speed and efficiency. We also feature  a deep integration with the Hugging Face Hub, allowing you to easily load and   share a dataset with the wider machine learning community.</p> <p>Find your dataset today on the Hugging Face Hub,  and take an in-depth look inside of it with the live viewer.</p>"}, {"location": "python/nlp/huggingface/#installation", "title": "Installation", "text": "<pre><code>pip install datasets\n</code></pre>"}, {"location": "python/nlp/huggingface/#load-datasets", "title": "Load datasets", "text": "<pre><code>from datasets import load_dataset, list_datasets\n\navailable = list_datasets()\n\n# load the dataset dynamically\nmovie_rationales = load_dataset(\"movie_rationales)\n\n# the object is a dict-like mapping of actual datasets\ntrain = movie_rationales[\"train]\ndf = train.to_pandas()\n</code></pre>"}, {"location": "python/packaging/setuptools/", "title": "Setuptools", "text": "", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#the-setuppy-python-file", "title": "The setup.py python file", "text": "<p><code>setup.py</code> is a Python file that provides information about a module/package that you have created. It's the build script for setuptools. It tells setuptools about your package (such as the name and version) as well as files to include.</p>", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#creating-a-basic-setuppy-file", "title": "Creating a Basic <code>setup.py</code> File", "text": "<p>Here's an example of a basic setup.py file:</p> <pre><code>from setuptools import setup, find_packages\n\nsetup(\n    name='MyPackage',\n    version='0.1',\n    packages=find_packages(),\n)\n</code></pre> <p>In this example, we're importing <code>setup</code> and <code>find_packages</code> from setuptools.  <code>setup</code> is the function that sets up your package, and <code>find_packages</code>  automatically discovers all packages and subpackages.</p> <p>The <code>name</code> argument is the name of your package, and <code>version</code> is the current version of your package.</p>", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#adding-more-information", "title": "Adding More Information", "text": "<p>We can add more information about our package in the setup.py file:</p> <pre><code>setup(\n    name='MyPackage',\n    version='0.1',\n    packages=find_packages(),\n    description='A sample Python package',\n    # you cand add this using a function from the requierements.txt\n    install_requires = [\"click==7.3.0\", \"colorama\"],\n    entry_points=\"\"\"\n    [console_scripts]\n    command1=src.main:command1\n    \"\"\"\n    long_description=open('README.txt').read(),\n    author='Your Name',\n    author_email='your.email@example.com',\n    url='http://example.com/MyPackage/',\n    license='LICENSE.txt',\n)\n</code></pre> <p>Here, description provides a short description of the package. <code>long_description</code>  can be a detailed description, which we are reading from a file named <code>README.txt</code>.  <code>author</code> and <code>author_email</code> are self-explanatory. <code>url</code> is the URL for the homepage  of the package. <code>license</code> specifies the license under which the package is released.</p>", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#including-additional-files-manifestin", "title": "Including Additional Files - `MANIFEST.in", "text": "<p>To include additional files such as the README, you can use the <code>MANIFEST.in</code> file. Create a file named <code>MANIFEST.in</code> in the same directory as setup.py and list any additional files you want to include in the package:</p> <pre><code>include README.txt\ninclude LICENSE.txt\n</code></pre> <p>You can also specify this directly in the setup.py file:</p> <pre><code>setup(\n    # \u2026\n    include_package_data=True,\n    package_data={\n       '': ['README.txt', 'LICENSE.txt'],\n    },\n)\n</code></pre> <p>Here, <code>include_package_data=True</code> tells setuptools to include any data files specified in package_data or <code>MANIFEST.in.</code></p>", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#installing-the-package", "title": "Installing the Package", "text": "<p>Once you've written your <code>setup.py</code>, you can install your package using <code>pip</code>:</p> <pre><code>pip install .\n</code></pre>", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#installing-editable", "title": "Installing editable", "text": "<p>This command installs the package in the current directory. If you want to install  the package in editable mode (i.e., changes to the source code are immediately  available without needing to reinstall the package), you can use:</p> PipPyhton <pre><code>pip install -e .\n</code></pre> <pre><code>python setup.py develop\n</code></pre>", "tags": ["Development", "Packaging"]}, {"location": "python/packaging/setuptools/#tutorials", "title": "Tutorials", "text": "<ul> <li>Setuptools official documentaion</li> </ul>", "tags": ["Development", "Packaging"]}]}